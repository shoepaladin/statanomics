{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This library has the following classes:\n",
    "\n",
    "- diagnostics.selection\n",
    "- diagnostics.balance\n",
    "- predQC\n",
    "- bootstrap\n",
    "- ate\n",
    "- ate.dml\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import scipy.stats \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression, Lasso, LassoCV, Ridge\n",
    "\n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os as os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard functions\n",
    "\n",
    "def predict_cv(dataset, split_name, n_data_splits, feature, x, model):\n",
    "    y_hat = []\n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (dataset[split_name] != r)\n",
    "        test = (dataset[split_name]==r)\n",
    "        lg = model.fit(dataset[feature][train==True],dataset[x][train==True])    \n",
    "        prediction = lg.predict(dataset[feature][test==True])\n",
    "        y_hat.extend(prediction)\n",
    "    return np.array(y_hat)\n",
    "\n",
    "\n",
    "\n",
    "def block_splits(data_est=pd.DataFrame(), split_name='splits', n_data_splits=4):\n",
    "    ## assign data-splitting based on a sequence.\n",
    "    ## This assumes the data is already randomly sorted, but it accommodates cases where the\n",
    "    ## propensity score or predicted outcome is already estimated\n",
    "    data_est[split_name] = np.zeros(len(data_est))\n",
    "    interval = int( len(data_est) / n_data_splits)\n",
    "    for p in range(n_data_splits):\n",
    "        lower = interval*p\n",
    "        upper = interval*(p+1)\n",
    "        if p==n_data_splits-1:\n",
    "            upper = len(data_est)\n",
    "        mask2 = np.zeros(len(data_est))\n",
    "        mask2[lower:upper] = 1\n",
    "        mask2 = pd.Series(mask2.astype(bool))\n",
    "        data_est.loc[mask2.to_list(), split_name] = p\n",
    "\n",
    "\n",
    "## Standardized Function for Predicting the Treatment Indicator.\n",
    "def predict_treatment_indicator(dataset, split_name, n_data_splits, feature,treatment, model):\n",
    "    treatment_hat = []\n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (dataset[split_name] != r)\n",
    "        test = (dataset[split_name]==r)\n",
    "        lg = model.fit(dataset[feature][train==True],dataset[treatment][train==True])\n",
    "        prediction = lg.predict_proba(dataset[feature][test==True])[:,1]\n",
    "        treatment_hat.extend(prediction)\n",
    "    return np.array(treatment_hat)\n",
    "\n",
    "## Standardized Function for Predicting Counterfactual Outcomes.\n",
    "def predict_counterfactual_outcomes(dataset, split_name, n_data_splits, feature, treatment, outcome,model):\n",
    "    yhat_treat = []\n",
    "    yhat_control = []\n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (dataset[split_name] != r)\n",
    "        test = (dataset[split_name]==r)            \n",
    "        bin_control = (dataset[treatment]==0)\n",
    "        bin_treat = (dataset[treatment]==1)        \n",
    "\n",
    "        ## Predict counterfactual outcomes for treatment\n",
    "        ols_treat=model.fit(dataset[feature][(bin_treat==True) & (train==True)], dataset[outcome][(bin_treat==True) & (train==True)]) \n",
    "        prediction = ols_treat.predict(dataset[feature][(test==True)])\n",
    "        yhat_treat.extend(prediction)\n",
    "        \n",
    "        ## Predict counterfactual outcomes for control\n",
    "        ols_control=model.fit(dataset[feature][(bin_control==True) & (train==True)], dataset[outcome][(bin_control==True) & (train==True)]) \n",
    "        prediction = ols_control.predict(dataset[feature][(test==True)])\n",
    "        yhat_control.extend(prediction)\n",
    "    return np.array(yhat_treat), np.array(yhat_control)\n",
    "\n",
    "def predict_continuous(dataset, split_name, n_data_splits, feature,outcome, model):\n",
    "    x_hat = []\n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (dataset[split_name] != r)\n",
    "        test = (dataset[split_name]==r)\n",
    "        lg = model.fit(dataset[feature][train==True],dataset[outcome][train==True])\n",
    "        prediction = lg.predict(dataset[feature][test==True])\n",
    "        x_hat.extend(prediction)\n",
    "    return np.array(x_hat)\n",
    " \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class predQC:\n",
    "    def treatment(metric= metrics.recall_score, \n",
    "                  t_true=np.ones(5), t_hat=np.zeros(5)):\n",
    "        return metric(t_true, t_hat)\n",
    "    def outcome(metric= metrics.r2_score, \n",
    "                ytrue=np.ones(5), yhat=np.zeros(5), treatment = np.array([0,1,1,0,1]) ):\n",
    "        overall = metric(ytrue, yhat)\n",
    "        t = metric(ytrue[(treatment==1)], yhat[(treatment==1)])\n",
    "        c = metric(ytrue[(treatment==0)], yhat[(treatment==0)])\n",
    "        return overall, t, c\n",
    "    def battery(ytrue,yhat,treatment,\n",
    "                t_true, t_hat,\n",
    "               tmetric,ymetric):\n",
    "        ymetrics=outcome(ymetric, ytrue, yhat, treatment)\n",
    "        return {'Treatment Status Metric Name':tmetric.__name__,\n",
    "                'Treatment Status Metric': treatment(tmetric, t_true, t_hat),\n",
    "                'Treatment Status N': len(t_true),                \n",
    "                'Outcome Metric':ymetric.__name__,\n",
    "                'Outcome Metric Overall': ymetrics[0],\n",
    "                'Outcome Metric Treatment': ymetrics[1],\n",
    "                'Outcome Metric Control': ymetrics[2] ,               \n",
    "                'Outcome N': len(ytrue),                \n",
    "                'Outcome Treatment N': (treatment==1).sum(),\n",
    "                'Outcome Control N': (treatment==0).sum()\n",
    "               }\n",
    "\n",
    "    def rmse(truth, estimate):\n",
    "        return     np.sqrt(np.sum( (truth-estimate)**2) / (len(truth)))\n",
    "\n",
    "    def mae(truth, estimate):\n",
    "        return np.sum( np.abs(truth-estimate)) / (len(truth))\n",
    "\n",
    "    def mape(truth,estimate):\n",
    "        return np.average( np.abs(truth - estimate)/truth ) \n",
    "\n",
    "    def r2(truth,estimate):\n",
    "        return np.sqrt(  np.corrcoef( truth, estimate)[0,1]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class secondstage:\n",
    "    lasso_max_iter = 1000\n",
    "    def second_stage(approach, test_data, train_data, covar_list, het_feature ):\n",
    "        '''\n",
    "        Outputs treatment estimates, standard errors, and OLS coefficient results    \n",
    "\n",
    "        For simplification, it runs the ols of 'y' ~ 'covar_list', where 'covar_list' is the heterogeneous features that includes interactions\n",
    "\n",
    "        where 'het_feature' is heterogeneous features. no interactions.\n",
    "        ''' \n",
    "\n",
    "        if approach=='OLS':\n",
    "            ## Now run OLS regression on the test set.\n",
    "            ## Predict the treatment assume all observations in the test set are treated.\n",
    "            X = sm.add_constant(train_data[covar_list])\n",
    "            finalmodel = sm.OLS(train_data['y'], X)\n",
    "            finalmodel_fit = finalmodel.fit()\n",
    "            ## To estimate the individual treatment, assume that all observations are treated.\n",
    "            X_test = pd.concat([test_data[['cons','ones']], test_data[het_feature] ], axis=1)\n",
    "            treatment_estimate = finalmodel_fit.predict( X_test )\n",
    "\n",
    "        elif approach=='CVLasso':\n",
    "            ## Train lasso on the training dataset, and recover the selected features.\n",
    "            ## As a default, keep the main treatment residual in the selected features.\n",
    "            X = sm.add_constant(train_data[covar_list])            \n",
    "\n",
    "            lasso_selection = LassoCV(cv=5, random_state=27, n_jobs=-1).fit(X, train_data['y'])\n",
    "            lasso_fit = Lasso(alpha=lasso_selection.alpha_, max_iter=lasso_max_iter).fit(X, train_data['y']) \n",
    "            selected_lasso_features = []\n",
    "            for x,b in zip(X.columns, lasso_fit.coef_):\n",
    "                if (b != 0) & (x!='const') & (x !='t'):\n",
    "                    selected_lasso_features.append(x)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            ## Now run OLS regression on the test set.\n",
    "            ## Predict the treatment assume all observations in the test set are treated.\n",
    "            X = sm.add_constant(test_data[['t']+selected_lasso_features])                    \n",
    "            finalmodel = sm.OLS(test_data['y'], X)\n",
    "            finalmodel_fit = finalmodel.fit()\n",
    "            ## To estimate the individual treatment, assume that all observations are treated.   \n",
    "            X_test = pd.concat([test_data[['cons','ones']], test_data[[h[3:] for h in selected_lasso_features]] ], axis=1)\n",
    "            treatment_estimate = finalmodel_fit.predict( X_test )\n",
    "        elif approach=='Lasso':\n",
    "            X = sm.add_constant(train_data[covar_list])            \n",
    "            lasso_fit = Lasso(alpha=lasso_alpha, max_iter=lasso_max_iter).fit(X, train_data['y'])            \n",
    "            selected_lasso_features = []\n",
    "            for x,b in zip(X.columns, lasso_fit.coef_):\n",
    "                if (b != 0) & (x!='const') & (x !='t'):\n",
    "                    selected_lasso_features.append(x)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            ## Now run OLS regression on the test set.\n",
    "            ## Predict the treatment assume all observations in the test set are treated.\n",
    "            X = sm.add_constant(test_data[['t']+selected_lasso_features])                    \n",
    "            finalmodel = sm.OLS(test_data['y'], X)\n",
    "            finalmodel_fit = finalmodel.fit()\n",
    "            ## To estimate the individual treatment, assume that all observations are treated.     \n",
    "            X_test = pd.concat([test_data[['cons','ones']], test_data[[h[3:] for h in selected_lasso_features]] ], axis=1)\n",
    "            treatment_estimate = finalmodel_fit.predict( X_test )\n",
    "\n",
    "        else:\n",
    "            print('Did not choose an option!')\n",
    "\n",
    "\n",
    "        ## Estimate standard errors on the test dataset\n",
    "        ## Want all of the variance-covariance matrix except for the intercept term.\n",
    "        var_cov = np.array(  finalmodel_fit.cov_params()  )[ 1:, 1:]\n",
    "\n",
    "        X1 = np.dot( np.array(X_test)[:,1:], var_cov)\n",
    "        output_se = np.sqrt( np.abs(np.dot( X1, np.array(finalmodel_fit.params[1:]).astype(float) ) ))    \n",
    "\n",
    "        ## Output dataframe of final stage OLS results\n",
    "        finalmodel_fit_coef = pd.DataFrame(index = finalmodel_fit.model.exog_names, data={'coef':finalmodel_fit.params, \n",
    "                                                                                           'se':finalmodel_fit.bse,\n",
    "                                                                                           'pvalue':finalmodel_fit.pvalues,\n",
    "                                                                                           'N':finalmodel_fit.model.nobs\n",
    "                                                                                          })    \n",
    "        return list(treatment_estimate), list(output_se), finalmodel_fit_coef\n",
    "\n",
    "    def second_stage_no_interactions(approach, test_data, train_data, het_feature ):\n",
    "        '''just like second_stage, but there are not interactions involved'''\n",
    "        if approach=='OLS':\n",
    "            ## Now run OLS regression on the test set.\n",
    "            ## Predict the treatment assume all observations in the test set are treated.\n",
    "            X = sm.add_constant(train_data[het_feature])\n",
    "            finalmodel = sm.OLS(train_data['y'], X)\n",
    "            finalmodel_fit = finalmodel.fit()\n",
    "            ## To estimate the individual treatment, assume that all observations are treated.\n",
    "            X_test = sm.add_constant(test_data[het_feature])\n",
    "            treatment_estimate = finalmodel_fit.predict( X_test )\n",
    "\n",
    "        elif approach=='CVLasso':\n",
    "            ## Train lasso on the training dataset, and recover the selected features.\n",
    "            ## As a default, keep the main treatment residual in the selected features.\n",
    "            X = sm.add_constant(train_data[het_feature])            \n",
    "\n",
    "            lasso_selection = LassoCV(cv=5, random_state=27, n_jobs=-1).fit(X, train_data['y'])\n",
    "            lasso_fit = Lasso(alpha=lasso_selection.alpha_, max_iter=lasso_max_iter).fit(X, train_data['y']) \n",
    "            selected_lasso_features = []\n",
    "            for x,b in zip(X.columns, lasso_fit.coef_):\n",
    "                if (b != 0) & (x!='const'):\n",
    "                    selected_lasso_features.append(x)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            ## Now run OLS regression on the test set.\n",
    "            ## Predict the treatment assume all observations in the test set are treated.\n",
    "            X_test = sm.add_constant(test_data[selected_lasso_features])                    \n",
    "            finalmodel = sm.OLS(test_data['y'], X_test)\n",
    "            finalmodel_fit = finalmodel.fit()\n",
    "            treatment_estimate = finalmodel_fit.predict( X_test )\n",
    "        elif approach=='Lasso':\n",
    "            X = sm.add_constant(train_data[het_feature])            \n",
    "            lasso_fit = Lasso(alpha=lasso_alpha, max_iter=lasso_max_iter).fit(X, train_data['y'])            \n",
    "            selected_lasso_features = []\n",
    "            for x,b in zip(X.columns, lasso_fit.coef_):\n",
    "                if (b != 0) & (x!='const'):\n",
    "                    selected_lasso_features.append(x)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            ## Now run OLS regression on the test set.\n",
    "            ## Predict the treatment assume all observations in the test set are treated.\n",
    "            X_test = sm.add_constant(test_data[selected_lasso_features])                    \n",
    "            finalmodel = sm.OLS(test_data['y'], X_test)\n",
    "            finalmodel_fit = finalmodel.fit()\n",
    "            treatment_estimate = finalmodel_fit.predict( X_test )        \n",
    "        else:\n",
    "            print('Did not choose an option!')\n",
    "        ## Estimate standard errors on the test dataset\n",
    "        ## Want all of the variance-covariance matrix except for the intercept term.\n",
    "        var_cov = np.array(  finalmodel_fit.cov_params()  )[ 1:, 1:]\n",
    "\n",
    "        X1 = np.dot( np.array(X_test)[:,1:], var_cov)\n",
    "        output_se = np.sqrt( np.abs(np.dot( X1, np.array(finalmodel_fit.params[1:]).astype(float) ) ))    \n",
    "\n",
    "        ## Output dataframe of final stage OLS results\n",
    "        finalmodel_fit_coef = pd.DataFrame(index = finalmodel_fit.model.exog_names, data={'coef':finalmodel_fit.params, \n",
    "                                                                                           'se':finalmodel_fit.bse,\n",
    "                                                                                           'pvalue':finalmodel_fit.pvalues,\n",
    "                                                                                           'N':finalmodel_fit.model.nobs\n",
    "                                                                                          })    \n",
    "        return list(treatment_estimate), list(output_se), finalmodel_fit_coef\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class bootstrap:\n",
    "    def reps(bootstrapreps, est_model, *args):\n",
    "        ate_est = []\n",
    "        ate_se = []\n",
    "        att_est = []\n",
    "        att_se = []        \n",
    "        for b in range(bootstrapreps):\n",
    "            bt_index = np.random.choice(len(args[0]), \n",
    "                                        len(args[0]),\n",
    "                                        replace=True)\n",
    "            df_bt = args[0].iloc[bt_index]        \n",
    "            est = est_model(df_bt, args[1], args[2],\n",
    "                     args[3], args[4],args[5],args[6], args[7],args[8])\n",
    "            ate_est.append(est['ATE TE'])\n",
    "            ate_se.append(est['ATE SE'])\n",
    "            att_est.append(est['ATT TE'])\n",
    "            att_se.append(est['ATT SE'])            \n",
    "        return ate_est, ate_se, att_est, att_se\n",
    "\n",
    "    def results(bt):\n",
    "        return np.average(bt), np.std(bt)\n",
    "    \n",
    "    def go_reps(bootstrapreps, est_model, *args):\n",
    "        reps_output = bootstrap.reps(bootstrapreps, est_model, *args)\n",
    "        ate_te = bootstrap.results(reps_output[0])\n",
    "        ate_se = bootstrap.results(reps_output[1])\n",
    "        att_te = bootstrap.results(reps_output[2])\n",
    "        att_se = bootstrap.results(reps_output[3])        \n",
    "        return {'model':est_model.__name__, \n",
    "                'ATE mean':ate_te[0], 'ATE std':ate_te[1],\n",
    "                'ATE SE mean':ate_se[0], 'ATE SE std':ate_se[1],\n",
    "                'ATT mean':ate_te[0], 'ATT std':ate_te[1],\n",
    "                'ATT SE mean':ate_se[0], 'ATT SE std':ate_se[1]               }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diagnostics:\n",
    "    \n",
    "    class selection:\n",
    "\n",
    "        def hdm_selection(data_est, \n",
    "                            feature_name, outcome_name, treatment_name):\n",
    "            '''    \n",
    "            data_set         (obj)    dataframe\n",
    "            feature_name     (list)   list of features to choose from\n",
    "            outcome_name     (str)    name of outcome in data_set\n",
    "            treatment_name   (str)    name of treatment in data_set\n",
    "\n",
    "            Run a cross-validated lasso regressions on the outcome and treatment to \n",
    "            select features that predict either or both.\n",
    "            '''    \n",
    "            selected_lasso_features = {}\n",
    "            selected_lasso_features['treatment'] = []\n",
    "            selected_lasso_features['outcome'] = []    \n",
    "            selection_coeff_names = pd.DataFrame()\n",
    "            for n,y in zip( ['outcome','treatment'], [outcome_name, treatment_name]):        \n",
    "                if n=='outcome':\n",
    "                    lasso_selection = LassoCV(cv=5, random_state=27, normalize=True, n_jobs=-1).fit(data_est[feature_name], data_est[y]) \n",
    "                    lasso_fit = Lasso(alpha=lasso_selection.alpha_, max_iter=200000).fit(data_est[feature_name], data_est[y]) \n",
    "                else:\n",
    "                    lasso_selection = LogisticRegressionCV(cv=5, random_state=27, penalty='l2', n_jobs=-1).fit(data_est[feature_name], data_est[y]) \n",
    "                    lasso_fit = LogisticRegression(C=lasso_selection.C_[0], penalty='l2', max_iter=200000).fit(data_est[feature_name], data_est[y])             \n",
    "                entry = pd.DataFrame(data={'type':n, 'features':feature_name, 'coef':lasso_fit.coef_.flatten()})\n",
    "                selection_coeff_names = selection_coeff_names.append(entry)\n",
    "                for x,b in zip(data_est[feature_name].columns, lasso_fit.coef_.flatten()):\n",
    "                    if (b != 0) & (x!='const') & (x !='t'):\n",
    "                        selected_lasso_features[n].append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "            unique_entries = list(selected_lasso_features.values())\n",
    "            return unique_entries, selected_lasso_features, selection_coeff_names\n",
    "\n",
    "\n",
    "    class balance:\n",
    "\n",
    "        def propensity_overlap(df, pscore, treatment):\n",
    "            '''\n",
    "            df         (DataFrame) dataframe name\n",
    "            pscore     (String)    name of propensity score in dataframe\n",
    "            treatment. (String)    name of treatment indicator in dataframe\n",
    "            '''\n",
    "            control = df.loc[df[treatment]==0][pscore]\n",
    "            treatment = df.loc[df[treatment]==1][pscore]\n",
    "            ## Plot propensity score\n",
    "            fig, ax = plt.subplots(nrows=2,ncols=1, figsize=(10,6), sharey=False, sharex=False)\n",
    "            t = ax[0].hist(treatment, density=True, bins=100, alpha=0.25, color='orange', label='T')\n",
    "            c = ax[0].hist(control, density=True, bins=100, alpha=0.25, color='blue', label='C')\n",
    "            ax[0].set_xlabel('Propensity Score')\n",
    "            ax[0].set_ylabel('Density')\n",
    "            ax[0].grid(True)\n",
    "            ax[0].legend()\n",
    "            ax[0].set_title(\"Distribution of Propensity Scores\")\n",
    "\n",
    "            t = ax[1].hist(1/ treatment, density=True, bins=100, alpha=0.25, color='coral', label='T')\n",
    "            c = ax[1].hist(1/ (1-control), density=True, bins=100, alpha=0.25, color='royalblue', label='C')\n",
    "            ax[1].set_xlabel('Inverse Propensity Weights')\n",
    "            ax[1].set_ylabel('Density')\n",
    "            ax[1].grid(True)\n",
    "            ax[1].legend()\n",
    "            ax[1].set_title(\"Distribution of Inverse Propensity Weights\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            for below in [0.01,0.05,0.10]:        \n",
    "                control_below =  np.sum( (control < below) )\n",
    "                treatment_below =  np.sum( (treatment < below) )    \n",
    "                print('   Control N below {0:5.2f}: {1}'.format(below, control_below))\n",
    "                print(' Treatment N below {0:5.2f}: {1}\\n'.format(below, treatment_below))        \n",
    "\n",
    "            for above in [0.90, 0.95, 0.99]:\n",
    "                control_below =  np.sum( (control > above) )\n",
    "                treatment_below =  np.sum( (treatment > above) )    \n",
    "                print('   Control N above {0:5.2f}: {1}'.format(above, control_below))\n",
    "                print(' Treatment N above {0:5.2f}: {1}\\n'.format(above, treatment_below))        \n",
    "\n",
    "\n",
    "        def feature_balance(df,\n",
    "                            feature_list, pscore, treatment,\n",
    "                           dml_ols, dml_model):\n",
    "            '''\n",
    "            df            (DataFrame) dataframe name\n",
    "            feature_list  (list)      list of feature names to check balance for.\n",
    "            pscore        (String)    name of propensity score in dataframe\n",
    "            treatment.    (String)    name of treatment indicator in dataframe\n",
    "            dml_ols.      (String)    {'DML','OLS'}\n",
    "            dml_model     (model)     Model to fit the feature.\n",
    "            '''    \n",
    "            control_data = df.loc[df[treatment]==0]\n",
    "            treatment_data = df.loc[df[treatment]==1]\n",
    "\n",
    "            ## Initialize the result dataframe\n",
    "            result_df = pd.DataFrame()\n",
    "\n",
    "            if dml_ols.upper()=='DML':\n",
    "                df['splits'] = np.random.choice(5,len(df), replace=True)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            ## Loop through each of the features\n",
    "            for x,i in zip(feature_list, range(len(feature_list))):\n",
    "                t_raw = treatment_data[x]\n",
    "                c_raw = control_data[x]\n",
    "\n",
    "                ## Remove the feature iterating over from the full list\n",
    "                feature_list_no_x = feature_list[:]\n",
    "                feature_list_no_x.remove(x)\n",
    "\n",
    "                ## Calculate simple differences between treatment and control\n",
    "                diff = np.average(t_raw) - np.average(c_raw)\n",
    "                diff_tstat, diff_pvalue = scipy.stats.ttest_ind(t_raw, c_raw)\n",
    "\n",
    "                ## Calculate the normalized difference\n",
    "                normalized_diff = diff / np.sqrt( np.var(t_raw) + np.var(c_raw)  )\n",
    "\n",
    "                ## Difference controlling for propensity score              \n",
    "\n",
    "                if dml_ols.upper()=='OLS':\n",
    "                    X = sm.add_constant( df[ [treatment] + [pscore]] ).astype(float)            \n",
    "                    OLS_pscore = sm.OLS( df[x] , X ).fit()\n",
    "                    ols_diff, ols_pvalue, ols_tstat = OLS_pscore.params[treatment], OLS_pscore.pvalues[treatment], OLS_pscore.tvalues[treatment]\n",
    "                elif dml_ols.upper()=='DML':\n",
    "                    X = sm.add_constant( df[treatment] - df[pscore] ).astype(float)            \n",
    "                    x_hat =  predict_cv(df, 'splits', 5, feature_list_no_x, x, dml_model)\n",
    "                    OLS_pscore = sm.OLS( df[x] - x_hat , X ).fit()\n",
    "                    ols_diff, ols_pvalue, ols_tstat = OLS_pscore.params.values[-1], OLS_pscore.pvalues.values[-1], OLS_pscore.tvalues.values[-1]\n",
    "\n",
    "\n",
    "                ## Calculate raw standardized difference\n",
    "                diff_sd = diff / df[x].std()\n",
    "\n",
    "                diff_tstat_sd, diff_pvalue_sd = scipy.stats.ttest_ind(t_raw/df[x].std(), c_raw/df[x].std())\n",
    "\n",
    "\n",
    "                ## SD Difference controlling for propensity score              \n",
    "                df['x_std'] = (df[x] - df[x].mean() )/df[x].std()\n",
    "                if dml_ols.upper()=='OLS':\n",
    "                    X = sm.add_constant( df[ [treatment] + [pscore]] ).astype(float)            \n",
    "                    OLS_pscore = sm.OLS( df['x_std'] , X ).fit()\n",
    "                    ols_diff_sd, ols_pvalue_sd, ols_tstat_sd = OLS_pscore.params[treatment], OLS_pscore.pvalues[treatment], OLS_pscore.tvalues[treatment]  \n",
    "                elif dml_ols.upper()=='DML':\n",
    "                    X = sm.add_constant( df[treatment] - df[pscore] ).astype(float)\n",
    "                    x_hat =  predict_cv(df, 'splits', 5, feature_list_no_x, 'x_std', dml_model)\n",
    "                    OLS_pscore = sm.OLS( df['x_std'] - x_hat , X ).fit()\n",
    "                    ols_diff_sd, ols_pvalue_sd, ols_tstat_sd = OLS_pscore.params.values[-1], OLS_pscore.pvalues.values[-1], OLS_pscore.tvalues.values[-1]  \n",
    "\n",
    "\n",
    "\n",
    "                row = pd.DataFrame(index=[i], data={'feature':x, \n",
    "                                                    'Raw Difference':diff, \n",
    "                                                    'Raw PValue': diff_pvalue, \n",
    "                                                    'Raw TStat': diff_tstat,\n",
    "                                                    'Normalized Diff': normalized_diff, \n",
    "                                                    'OLS-PScore Difference': ols_diff, \n",
    "                                                    'OLS-PScore PValue': ols_pvalue, \n",
    "                                                    'OLS-PScore TStat': ols_tstat,\n",
    "                                                    'Raw Difference SD':diff_sd, \n",
    "                                                    'Raw PValue SD': diff_pvalue_sd, \n",
    "                                                    'Raw TStat SD': diff_tstat_sd,\n",
    "                                                    'OLS-PScore Difference SD': ols_diff_sd, \n",
    "                                                    'OLS-PScore PValue SD': ols_pvalue_sd, \n",
    "                                                    'OLS-PScore TStat SD': ols_tstat_sd                                            \n",
    "                                                   })\n",
    "                result_df = result_df.append(row)\n",
    "            result_df.sort_values(by='feature', inplace=True)\n",
    "\n",
    "            try:\n",
    "                df.drop(columns=['x_std'], inplace=True)        \n",
    "                df.drop(columns=['x_std'], inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            return result_df\n",
    "\n",
    "\n",
    "        def summarize_result_df(result_df):\n",
    "\n",
    "            all_differences = result_df[['Raw Difference SD','OLS-PScore PValue SD']].abs().describe()\n",
    "            stat_sig_raw_differences = result_df.loc[ result_df['Raw PValue SD'] < 0.05]['Raw Difference SD'].abs().describe()\n",
    "            a = stat_sig_raw_differences.to_frame()\n",
    "            a.rename(columns={\"Raw Difference SD\": \"Stat Sig Raw Difference SD\"}, inplace=True)\n",
    "\n",
    "            stat_sig_raw_differences = result_df.loc[ result_df['OLS-PScore PValue SD'] < 0.05]['OLS-PScore Difference SD'].abs().describe()\n",
    "            b = stat_sig_raw_differences.to_frame()\n",
    "            b.rename(columns={\"OLS-PScore Difference SD\": \"Stat Sig OLS-PScore Difference SD\"}, inplace=True)\n",
    "\n",
    "            return pd.concat([all_differences, a, b], axis=1)     \n",
    "\n",
    "\n",
    "        def plot_difference(results_df, figuresize):\n",
    "            fig, ax = plt.subplots(figsize=figuresize)  # Create the figure    \n",
    "            y_pos = range( len(results_df) )\n",
    "            values = results_df['feature']\n",
    "            diff_sd =  results_df['Raw Difference SD'].abs() \n",
    "\n",
    "            diff_ols_sd =  results_df['OLS-PScore Difference SD'].abs() \n",
    "\n",
    "            diff_sd_se = results_df['Raw Difference SD'].abs() / results_df['Raw TStat SD'].abs()\n",
    "            diff_ols_se = results_df['OLS-PScore Difference SD'].abs() / results_df['OLS-PScore TStat SD'].abs()    \n",
    "\n",
    "            diff_sd_ci95_upper,diff_sd_ci95_lower = diff_sd + 1.96*diff_sd_se , diff_sd - 1.96*diff_sd_se\n",
    "            diff_ols_ci95_upper,diff_ols_ci95_lower = diff_ols_sd + 1.96*diff_ols_se , diff_ols_sd - 1.96*diff_ols_se    \n",
    "\n",
    "            rects = ax.barh( values, diff_sd , color='blue',alpha=0.25, label='Raw')    \n",
    "            hlines= ax.hlines( values, diff_sd_ci95_lower, diff_sd_ci95_upper,\n",
    "                              colors='blue', linestyles='solid', label='95% CI')\n",
    "\n",
    "\n",
    "            rects = ax.barh( values, diff_ols_sd , color='red', alpha=0.25, label='Controlled')\n",
    "            hlines= ax.hlines( values, diff_ols_ci95_lower, diff_ols_ci95_upper,\n",
    "                              colors='red', linestyles='solid', label='95% CI')\n",
    "\n",
    "            ax.legend()\n",
    "            ax.set_xlabel('Abs of Standardized Difference')\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels(values)\n",
    "            ax.invert_yaxis()  # labels read top-to-bottom        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class ate:\n",
    "    def ols_vanilla(data_est, \n",
    "                split_name, feature_name, outcome_name, treatment_name,\n",
    "                ymodel,tmodel,\n",
    "               n_data_splits, aux_dictionary ):\n",
    "        ols = sm.OLS(data_est[outcome_name], sm.add_constant(data_est[[treatment_name]+feature_name]) ).fit()\n",
    "        return {'ATE TE':ols.params[1], 'ATE SE': ols.bse[1],'ATT TE':ols.params[1], 'ATT SE': ols.bse[1]}\n",
    "\n",
    "\n",
    "\n",
    "    def propbinning(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary):\n",
    "        main_result = ate.propbinning_main(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary)\n",
    "        pbin_bt_results = bootstrap.go_reps(aux_dictionary['bootstrapreps'], ate.propbinning_main, data_est, \n",
    "                        split_name, feature_name, outcome_name, treatment_name,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits,\n",
    "                       aux_dictionary)\n",
    "        return {'ATE TE':pbin_bt_results['ATE mean'], 'ATE SE': pbin_bt_results['ATE std'],            'ATT TE':pbin_bt_results['ATT mean'], 'ATT SE': pbin_bt_results['ATT std'], 'PScore':main_result['PScore']}\n",
    "\n",
    "    def propbinning_main(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary):\n",
    "\n",
    "        block_splits(data_est, split_name, n_data_splits)\n",
    "\n",
    "        ## Predict Treatment\n",
    "        that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "        data_est['that'] = that\n",
    "\n",
    "        ## Sort by the probabilities and split into bins.\n",
    "        ## For each bin, estimate counterfactuals for the treatment and control groups.\n",
    "        data_est['that_bin'] = pd.qcut(data_est['that'], q=aux_dictionary['n_bins'], labels=False)    \n",
    "        min_size = data_est['that_bin'].value_counts().min()\n",
    "\n",
    "        data_est = data_est.sort_values(by=['that_bin',split_name])\n",
    "\n",
    "        yhat_treat = []\n",
    "        yhat_control = []\n",
    "        for b in range(aux_dictionary['n_bins']):\n",
    "            ## Use the first and last entry of each bin as cutpoints.    \n",
    "            bin_of_interest = (data_est['that_bin']==b)\n",
    "            for r in np.arange(n_data_splits):\n",
    "                train = (bin_of_interest==True) & (data_est[split_name] != r)\n",
    "                test = (bin_of_interest==True) & (data_est[split_name]==r)            \n",
    "                bin_control = (bin_of_interest==True) & (data_est[treatment_name]==0)\n",
    "                bin_treat = (bin_of_interest==True) & (data_est[treatment_name]==1)        \n",
    "\n",
    "                ## Predict counterfactual outcomes for treatment\n",
    "                ols_treat=ymodel.fit(data_est[feature_name][(bin_treat==True) & (train==True)], data_est[outcome_name][(bin_treat==True) & (train==True)]) \n",
    "                tpred = ols_treat.predict(data_est[feature_name][(test==True) ])\n",
    "                yhat_treat.extend(tpred)\n",
    "\n",
    "                ## Predict counterfactual outcomes for control\n",
    "                ols_control=ymodel.fit(data_est[feature_name][(bin_control==True) & (train==True)], data_est[outcome_name][(bin_control==True) & (train==True)]) \n",
    "                cpred = ols_control.predict(data_est[feature_name][(test==True)])\n",
    "                yhat_control.extend(cpred)\n",
    "\n",
    "        ## Take the difference between the counterfactuals\n",
    "        treatment_estimate = np.array(yhat_treat) - np.array(yhat_control)\n",
    "\n",
    "        ## Output the treatment estimate and propensity scores\n",
    "        return {'ATE TE':np.average(treatment_estimate), 'ATE SE': np.std(treatment_estimate),            'ATT TE':np.average(treatment_estimate[(data_est[treatment_name]==1)]), 'ATT SE': np.std(treatment_estimate[(data_est[treatment_name]==1)]),            'PScore':that}\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Inverse-propensity weighting:\n",
    "    estimator, where asympotics come from Hirano, Imbens, Ridder (2004) Econometrica: \n",
    "    https://scholar.harvard.edu/imbens/files/efficient_estimation_of_average_treatment_effects_using_the_estimated_propensity_score.pdf\n",
    "\n",
    "    '''\n",
    "\n",
    "    def ipw_main(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary):\n",
    "        block_splits(data_est, split_name, n_data_splits)\n",
    "\n",
    "        ## 1st Stage: Predict treatment indicator\n",
    "        that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "\n",
    "        keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "\n",
    "        ipw_a = (data_est[outcome_name] / that)*(data_est[treatment_name]==1)\n",
    "        ipw_b = (data_est[outcome_name] / (1-that))*(data_est[treatment_name]==0)\n",
    "\n",
    "        ipw_a_att = ipw_a * that\n",
    "\n",
    "        results = np.average(ipw_a[keep_these] - ipw_b[keep_these]), np.std(ipw_a[keep_these] - ipw_b[keep_these] ),        np.average( (ipw_a[keep_these] - ipw_b[keep_these])*that ),  np.std( (ipw_a[keep_these] - ipw_b[keep_these])*that ),        that\n",
    "\n",
    "        return {'ATE TE':results[0], 'ATE SE': results[1], 'ATT TE':results[2], 'ATT SE': results[3], 'PScore':results[4]}\n",
    "\n",
    "\n",
    "    def ipw(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary):\n",
    "        main_result = ate.ipw_main(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary)\n",
    "        ipw_bt_results = bootstrap.go_reps(aux_dictionary['bootstrapreps'], ate.ipw_main, data_est, \n",
    "                        split_name, feature_name, outcome_name, treatment_name,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits,\n",
    "                       aux_dictionary)\n",
    "        return {'ATE TE':ipw_bt_results['ATE mean'], 'ATE SE': ipw_bt_results['ATE std'], 'ATT TE':ipw_bt_results['ATT mean'], 'ATT SE': ipw_bt_results['ATT std'], 'PScore': main_result['PScore']}\n",
    "\n",
    "\n",
    "    # In[36]:\n",
    "\n",
    "\n",
    "    '''\n",
    "    https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.WLS.html\n",
    "    weightsarray_like, optional\n",
    "\n",
    "        A 1d array of weights. If you supply 1/W then the variables are pre- multiplied by 1/sqrt(W). \n",
    "        If no weights are supplied the default value is 1 and WLS results are the same as OLS.\n",
    "\n",
    "    '''\n",
    "    def ipw_wls(data_est, \n",
    "                    split_name, feature_name, outcome_name, treatment_name,\n",
    "                    ymodel,tmodel,\n",
    "                   n_data_splits,\n",
    "                   aux_dictionary):\n",
    "        block_splits(data_est, split_name, n_data_splits)\n",
    "\n",
    "        ## 1st Stage: Predict treatment indicator\n",
    "        that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "\n",
    "        keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "\n",
    "        ipw_weights = data_est[treatment_name] / that + (1-data_est[treatment_name]) / (1-that)\n",
    "\n",
    "        wls = sm.WLS(data_est[outcome_name][keep_these],\n",
    "               sm.add_constant(data_est[treatment_name])[keep_these],\n",
    "               weights = ipw_weights[keep_these]\n",
    "              ).fit()\n",
    "\n",
    "        ipw_att_weights = data_est[treatment_name]  + (1-data_est[treatment_name])*that / (1-that)\n",
    "\n",
    "        wls_att = sm.WLS(data_est[outcome_name][keep_these],\n",
    "               sm.add_constant(data_est[treatment_name])[keep_these],\n",
    "               weights = ipw_att_weights[keep_these]\n",
    "              ).fit()\n",
    "\n",
    "\n",
    "        return {'ATE TE':wls.params[1], 'ATE SE': wls.bse[1], 'ATT TE':wls_att.params[1], 'ATT SE': wls_att.bse[1], 'PScore':that}    \n",
    "    \n",
    "    \n",
    "    class dml:\n",
    "\n",
    "        def dml_plm(data_est, \n",
    "                        split_name, feature_name, outcome_name, treatment_name,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits,\n",
    "                       aux_dictionary):\n",
    "\n",
    "            block_splits(data_est, split_name, n_data_splits)\n",
    "\n",
    "            ## 1st Stage: Predict treatment indicator\n",
    "            if ('that' in aux_dictionary.keys() ):\n",
    "                if (aux_dictionary['that'] != None).any():\n",
    "                    that = aux_dictionary['that'][:]\n",
    "            else:\n",
    "                that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "\n",
    "            ## Residualize outcome\n",
    "            if ('yhat' in aux_dictionary.keys() ):\n",
    "                if (aux_dictionary['yhat'] != None).any():\n",
    "                    outcome_hat = aux_dictionary['yhat'][:]\n",
    "\n",
    "            else:\n",
    "                ## Create and sort by splits\n",
    "                outcome_hat = []        \n",
    "                for r in np.arange(n_data_splits):\n",
    "                    train = (data_est[split_name] != r)\n",
    "                    test = (data_est[split_name]==r)\n",
    "                    ols = ymodel.fit(data_est[feature_name][train==True],data_est[outcome_name][train==True])\n",
    "                    prediction = ols.predict(data_est[feature_name][test==True])\n",
    "                    outcome_hat.extend(prediction)\n",
    "\n",
    "                outcome_hat = np.array(outcome_hat)\n",
    "\n",
    "            treatment_residual = data_est[treatment_name].to_numpy() - that\n",
    "            outcome_residual = data_est[outcome_name].to_numpy() - outcome_hat\n",
    "\n",
    "            ## shave off propensity scores below and under certain thresholds\n",
    "            keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "            ## Second stage OLS, for a partial linear model\n",
    "            X = sm.add_constant(treatment_residual[keep_these])\n",
    "            finalmodel_fit = sm.OLS( list(outcome_residual[keep_these]), X).fit()\n",
    "\n",
    "            return {'ATE TE':finalmodel_fit.params[-1], 'ATE SE': finalmodel_fit.bse[-1],         'ATT TE':finalmodel_fit.params[-1], 'ATT SE': finalmodel_fit.bse[-1], 'PScore':that}\n",
    "\n",
    "\n",
    "        # In[39]:\n",
    "\n",
    "\n",
    "        def dml_irm(data_est, \n",
    "                        split_name, feature_name, outcome_name, treatment_name,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits, aux_dictionary ):\n",
    "            block_splits(data_est, split_name, n_data_splits)\n",
    "\n",
    "\n",
    "            ## 1st Stage: Predict treatment indicator\n",
    "            if ('that' in aux_dictionary.keys() ):\n",
    "                if (aux_dictionary['that'] != None):\n",
    "                    that = aux_dictionary['that'][:]\n",
    "            else:\n",
    "                that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "\n",
    "            ## 2nd Stage: Predict counterfactual outcomes\n",
    "            yhat_treat, yhat_control = predict_counterfactual_outcomes(data_est, split_name, n_data_splits, feature_name, treatment_name, outcome_name,ymodel)\n",
    "\n",
    "            ## Residualize:\n",
    "            y_control_residual = data_est[outcome_name]- yhat_control\n",
    "            y_treat_residual = data_est[outcome_name]- yhat_treat    \n",
    "\n",
    "            #####\n",
    "            ## ATE Estimator on the residuals\n",
    "            #####\n",
    "            ra_term = yhat_treat - yhat_control    \n",
    "\n",
    "            first_fraction = (data_est[treatment_name]==1)*(y_treat_residual) / that\n",
    "            second_fraction = (data_est[treatment_name]==0)*(y_control_residual) / (1-that)\n",
    "            ipw_term = first_fraction - second_fraction\n",
    "\n",
    "            treatment_estimate = ra_term + ipw_term\n",
    "            keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "\n",
    "            treatment_estimate = treatment_estimate[keep_these]\n",
    "\n",
    "            ## standard error\n",
    "            score = treatment_estimate - np.mean(treatment_estimate)\n",
    "            j0 = 1 - 2*np.mean(score)+ np.mean(score**2)\n",
    "            var_hat = j0**(-1) * np.mean(score**2)\n",
    "            var_hat = np.std(score)\n",
    "\n",
    "            ## ATE Standard error.\n",
    "            score = treatment_estimate - np.mean(treatment_estimate)\n",
    "            var_hat = 0   \n",
    "            for r in np.arange(n_data_splits):\n",
    "                here = score[data_est[split_name]==r]\n",
    "                add_to = np.mean(here**2) * (1 / n_data_splits)\n",
    "                var_hat += add_to\n",
    "            SE = np.sqrt(var_hat) /np.sqrt(len(data_est))\n",
    "\n",
    "            #####\n",
    "            ## ATT Estimator on the residuals\n",
    "            #####      \n",
    "            prob_unconditional = (data_est[treatment_name].mean())\n",
    "            att_first_fraction = (data_est[treatment_name]==1)*(y_control_residual)/prob_unconditional\n",
    "            att_second_fraction = (that)*(data_est[treatment_name]==0)*(y_control_residual)/( that* (prob_unconditional) )\n",
    "\n",
    "            treatment_estimate_att = att_first_fraction - att_second_fraction\n",
    "\n",
    "            ## ATE Standard error.\n",
    "            score = treatment_estimate_att - np.mean(treatment_estimate_att)\n",
    "            var_hat = 0   \n",
    "            for r in np.arange(n_data_splits):\n",
    "                here = score[data_est[split_name]==r]\n",
    "                add_to = np.mean(here**2) * (1 / n_data_splits)\n",
    "                var_hat += add_to\n",
    "            SE_ATT = np.sqrt(var_hat) /np.sqrt(len(data_est))\n",
    "\n",
    "            return {'ATE TE':np.mean(treatment_estimate), 'ATE SE': SE,         'ATT TE':np.mean(treatment_estimate_att), 'ATT SE': SE_ATT, 'PScore':that}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class hte:\n",
    "    class other:\n",
    "        '''\n",
    "        Based on \"Optimal doubly robust estimation of heterogeneous causal effects\" \n",
    "        from https://arxiv.org/abs/2004.14497\n",
    "        note that this does not do the kernel weighting version needed.\n",
    "        This version can either output the pseudo_outcome, for which standard errors are not provided.\n",
    "\n",
    "\n",
    "        aux_dictionary['force_second_stage']    (str) {None, 'OLS','CVLasso', 'Lasso'}\n",
    "            None   -  provides the pseudo-outcomes, no standard errors provided!\n",
    "            'OLS'  -  does the second stage OLS regression \n",
    "            'CVLasso' - does feature selection with CV Lasso and OLS regression with a two-way split\n",
    "            'Lasso' - does feature selection with a Lasso and OLS regression with a two-way split\n",
    "        '''\n",
    "\n",
    "        def DR(data_est, \n",
    "                        feature_name, outcome_name, treatment_name,\n",
    "                        het_feature,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits, \n",
    "                         aux_dictionary):\n",
    "            block_splits(data_est, 'splits', n_data_splits)\n",
    "\n",
    "            ## Calculate propensity score\n",
    "            that = predict_treatment_indicator(data_est, 'splits', n_data_splits, feature_name,treatment_name, tmodel)\n",
    "\n",
    "            ## Calculcate the counterfactual outcomes\n",
    "            yhat_treat, yhat_control = predict_counterfactual_outcomes(data_est, 'splits', n_data_splits, feature_name, treatment_name, outcome_name,ymodel)\n",
    "\n",
    "            ra_portion = yhat_treat - yhat_control\n",
    "            adj_treatment = (data_est[treatment_name]==1)*(data_est[outcome_name] - yhat_treat)/that\n",
    "            adj_control = (data_est[treatment_name]==0)*(data_est[outcome_name] - yhat_control)/(1-that)\n",
    "\n",
    "            pseudo_outcome = ra_portion - adj_treatment + adj_control\n",
    "\n",
    "            output_baseline_hat = yhat_control[:]\n",
    "\n",
    "            if (aux_dictionary['force_second_stage']==None):\n",
    "                output_treatment_estimate = pseudo_outcome[:]\n",
    "                output_se_hat = np.ones(len(pseudo_outcome))*(-1)\n",
    "\n",
    "                other_output = {}\n",
    "            else:\n",
    "                approach = aux_dictionary['force_second_stage']\n",
    "\n",
    "                ols_coef_pd = {}\n",
    "\n",
    "                data_for_2nd_stage = data_est.copy()\n",
    "                data_for_2nd_stage['y'] = pseudo_outcome[:]\n",
    "                data_for_2nd_stage['t'] = data_est[treatment_name].copy()\n",
    "\n",
    "                data_for_2nd_stage['half'] = 0\n",
    "                half = np.int(len(data_for_2nd_stage) / 2)\n",
    "                data_for_2nd_stage.loc[data_for_2nd_stage.iloc[-half:].index, 'half' ] = 1\n",
    "\n",
    "                data_for_2nd_stage['cons'] = 1\n",
    "                data_for_2nd_stage['ones'] = 1\n",
    "\n",
    "                data_est_half = {'0': data_for_2nd_stage.loc[data_for_2nd_stage['half']==0], \n",
    "                               '1': data_for_2nd_stage.loc[data_for_2nd_stage['half']==1]}            \n",
    "                output_treatment_estimate = []\n",
    "                output_se_hat = []        \n",
    "                for test_i,train_i in zip(['0','1'], ['1','0']):            \n",
    "                    test_data = data_est_half[test_i]\n",
    "                    train_data = data_est_half[train_i]\n",
    "                    treatment_estimate,se_estimate, coef_pd = secondstage.second_stage_no_interactions(approach, test_data, train_data, het_feature )                    \n",
    "                    output_treatment_estimate.extend(list(treatment_estimate))            \n",
    "                    output_se_hat.extend(list(se_estimate))            \n",
    "                    ols_coef_pd[test_i] = coef_pd.copy()\n",
    "\n",
    "                other_output = {'coefficients':ols_coef_pd}\n",
    "    #                             'Treatment outcome metric':t_r2, \n",
    "    #                             'Outcome prediction metric':y_r2}\n",
    "\n",
    "            ## Output the treatment estimate and propensity scores\n",
    "            return output_treatment_estimate, output_se_hat, that, output_baseline_hat, other_output    \n",
    "\n",
    "\n",
    "        def het_ols(data_est, \n",
    "                            feature_name, outcome_name, treatment_name,\n",
    "                            het_feature,\n",
    "                            ymodel,tmodel,\n",
    "                           n_data_splits, \n",
    "                             force_second_stage):\n",
    "            block_splits(data_est, 'splits', n_data_splits)        \n",
    "            output_treatment_estimate = []\n",
    "            output_se_hat = []\n",
    "            that = []\n",
    "            output_baseline_hat = []\n",
    "\n",
    "            ## Create interactions of each feature with treatment.\n",
    "            het_interactions = []\n",
    "            for x in het_feature:\n",
    "                data_est[x+'_x'] = data_est[treatment_name]*data_est[x]\n",
    "                het_interactions.append(x + '_x')\n",
    "\n",
    "\n",
    "            ## Run fully interacted regression\n",
    "            for r in np.arange(n_data_splits):\n",
    "                train = data_est.loc[ data_est['splits'] != r ]\n",
    "                test = data_est.loc[ data_est['splits'] == r ] \n",
    "\n",
    "                ## Estimate regression on the training dataset\n",
    "                X = sm.add_constant(train[feature_name + [treatment_name] + het_interactions])\n",
    "                finalmodel = sm.OLS(train[outcome_name], X)\n",
    "                finalmodel_fit = finalmodel.fit()\n",
    "\n",
    "                ## Estimate treatment effects on the test dataset\n",
    "                treatment_effects = dict(finalmodel_fit.params)    \n",
    "                treatment_estimates = np.zeros(len(test))\n",
    "                het_treatment_effects = []\n",
    "                for x in treatment_effects.keys():\n",
    "                    if x=='T':\n",
    "                        treatment_estimates += treatment_effects[x]\n",
    "                        het_treatment_effects.append(treatment_effects[x])\n",
    "                    elif x in het_interactions:\n",
    "                        treatment_estimates += treatment_effects[x]*test[x.replace('_x','')]\n",
    "                        het_treatment_effects.append(treatment_effects[x])\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                ## Estimate standard errors on the test dataset\n",
    "                var_cov = np.array(  finalmodel_fit.cov_params()  )[ -1 * len(het_interactions) - 1:, -1 * len(het_interactions) - 1:]\n",
    "                output_se = np.sqrt( np.abs(np.dot( np.dot( test[[treatment_name] + het_interactions], var_cov), np.array(het_treatment_effects).astype(float) ) ))\n",
    "\n",
    "                ## Estimate baseline\n",
    "                output_baseline = test[outcome_name] - test[treatment_name]*treatment_estimates\n",
    "                output_treatment_estimate.extend(treatment_estimates.tolist())\n",
    "                output_se_hat.extend(output_se.tolist())\n",
    "                output_baseline_hat.extend(output_baseline.tolist())\n",
    "\n",
    "            return output_treatment_estimate, output_se_hat, that, output_baseline_hat\n",
    "\n",
    "\n",
    "\n",
    "    # #### Generalized Random Forest Models.\n",
    "    # I am basically doing a wrapper for _econml_'s implementation of GRF.\n",
    "    # Check out it's documentation here: https://econml.azurewebsites.net/_autosummary/econml.grf.CausalForest.html\n",
    "    # ***\n",
    "    # **inputs specific to GRF**\n",
    "    # \n",
    "    #     criterion       'mse','het', default='mse'\n",
    "    #     honest           (default=True) whether trees should be trained in an honest manner.\n",
    "    #     inference        (default=True) whether inference should be ienabled via out-of-bag bootstrap\n",
    "    #     subforest_size   (default=4) The number of trees in each sub-forest that is used in the bootstrap-of-little-bags calculation. The parameter n_estimators must be divisible by subforest_size. Should typically be a small constant. \n",
    "    # \n",
    "    # **these are standard forest inputs, so I won't define them here**\n",
    "    # \n",
    "    #     n_estimators     number of trees\n",
    "    #     max_depth\n",
    "    #     min_samples_split\n",
    "    #     min_samples_leaf\n",
    "    #     min_weight_fraction_leaf\n",
    "    #     min_var_fraction_leaf\n",
    "    #     min_var_leaf_on_val\n",
    "    #     max_features\n",
    "    #     min_impurity_decrease\n",
    "    #     max_samples\n",
    "    #     min_balancedness_tol\n",
    "    #     fit_intercept\n",
    "    #     n_jobs\n",
    "    #     random_state\n",
    "    #     verbose\n",
    "    #     warm_start\n",
    "    # \n",
    "    # \n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[21]:\n",
    "\n",
    "\n",
    "    from econml.grf import CausalForest, RegressionForest\n",
    "\n",
    "    class trees:\n",
    "    ## predict() >> predict_full() or predict_tree_average >> predict_tree_average_full\n",
    "    ## predict(X) returns the prefix of relevant fitted local parameters\n",
    "    ##.   theta(X)[1,...,n_relevant_outputs], [lb(x),ub(x)]\n",
    "    ## predict_full(X, interval=False, alpha=0.05) - returns fitted local parameters for each x in X: \n",
    "    ##.   theta(x), [lb(x), ub(x)]\n",
    "    ## predict_interval(X, alpha=0.05)\n",
    "    ##.   lb(x), ub(x)\n",
    "    ## predict_tree_average(X) returns the prefix of relevant fitted parameters for each X. The average of parameters estimates by each tree.\n",
    "    ##.   theta(X)[1,...,n_relevant_outputs]\n",
    "    ## predict_tree_average_full(X) returns the fitted local parameter for each X\n",
    "    ##.   theta(x), [lb(x), ub(x)]\n",
    "    ##\n",
    "    ## predict_var()  returns the covariate matrix\n",
    "    ## prediction_stderr() returns the standard error of each coordiate of the prefix\n",
    "    ##\n",
    "    ## predict_alpha_and_jac(X, slice=None, parallel=True)  Return the value of the conditional jacobian E[J | X=x] and the conditional alpha E[A | X=x] using the forest as kernel weight.\n",
    "    ##    alpha, jac\n",
    "\n",
    "        def grf(data_est, \n",
    "                        feature_name, outcome_name, treatment_name,\n",
    "                        het_feature,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits, \n",
    "                         aux_dictionary):\n",
    "\n",
    "            for x,y in zip( ['criterion','n_estimators','n_jobs'], ['mse',100, 10] ):\n",
    "                if x in aux_dictionary.keys():\n",
    "                    pass\n",
    "                else:\n",
    "                    aux_dictionary[x] = y\n",
    "\n",
    "            ## Estimate a propensity score model using RegressionForest\n",
    "            grf_rf = RegressionForest(n_estimators=aux_dictionary['n_estimators'], \n",
    "                            honest=True, \n",
    "                            inference=True, \n",
    "                            n_jobs=aux_dictionary['n_jobs'])\n",
    "            grf_rf_fit = grf_rf.fit(data_est[feature_name], data_est[treatment_name])\n",
    "            that = grf_rf_fit.predict(data_est[feature_name]).flatten()\n",
    "\n",
    "            grf_rf_fit = grf_rf.fit(data_est.loc[data_est[treatment_name]==0][feature_name], \n",
    "                                    data_est.loc[data_est[treatment_name]==0][outcome_name])        \n",
    "            output_baseline_hat = grf_rf_fit.predict(data_est[feature_name]) .flatten()\n",
    "\n",
    "\n",
    "            ## Estimate the causal forest to get treatment effect estimates\n",
    "            cf=CausalForest(n_estimators=aux_dictionary['n_estimators'], \n",
    "                            criterion=aux_dictionary['criterion'],\n",
    "                            honest=True, \n",
    "                            inference=True, \n",
    "                            fit_intercept=True, n_jobs=aux_dictionary['n_jobs'])\n",
    "            cf_fit = cf.fit(data_est[feature_name], data_est[treatment_name], data_est[outcome_name])\n",
    "\n",
    "            output_treatment_estimate = cf_fit.predict(data_est[feature_name], interval=True, alpha=0.05)[0]\n",
    "            output_se_hat = cf_fit.prediction_stderr(data_est[feature_name])\n",
    "            alpha,jac = cf_fit.predict_alpha_and_jac(data_est[feature_name],parallel=True)\n",
    "            other_output = {'alpha':alpha, 'jac':jac, 'hte_feature_importance':cf_fit.feature_importances_}\n",
    "\n",
    "            return output_treatment_estimate, output_se_hat, that, output_baseline_hat,other_output\n",
    "\n",
    "\n",
    "    class het_dml_approaches:\n",
    "        ## Approach 1\n",
    "        def HR(data_est, \n",
    "                        feature_name, outcome_name, treatment_name,\n",
    "                        het_feature,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits, \n",
    "                         aux_dictionary):\n",
    "            '''    \n",
    "            aux_dictionary['force_second_stage']    (str) {None, 'OLS','CVLasso', 'Lasso'}\n",
    "            '''    \n",
    "            block_splits(data_est, 'splits', n_data_splits)\n",
    "\n",
    "            ## 1st Stage: Predict treatment indicator\n",
    "            that = predict_treatment_indicator(data_est, 'splits', n_data_splits, feature_name,treatment_name, tmodel)\n",
    "            ## 1st Stage: Predict treatment indicator interacted with each feature\n",
    "            ## remember to remove the feature interacted with the treatment as a predictor\n",
    "            residual_treatment_hat = [data_est[treatment_name] - that]\n",
    "            for x in het_feature:\n",
    "                data_est[x+'_x'] = data_est[treatment_name]*data_est[x]\n",
    "                treatment_hat = []\n",
    "                for r in np.arange(n_data_splits):\n",
    "                    train = (data_est['splits'] != r)\n",
    "                    test = (data_est['splits']==r)\n",
    "                    ols_pred = ymodel.fit(data_est[feature_name][train==True],\n",
    "                                                    data_est[x+'_x'][train==True])\n",
    "                    prediction = ymodel.predict(data_est[feature_name][test==True])\n",
    "                    treatment_hat.extend(prediction)            \n",
    "\n",
    "                diff = data_est[x+'_x'] - treatment_hat \n",
    "                residual_treatment_hat.append(diff)        \n",
    "\n",
    "            ## 1st Stage: Predict the outcome\n",
    "            ## Train a model on a training set, and predict onto the test set.\n",
    "            outcome_hat = []\n",
    "            output_baseline_hat = []\n",
    "            for r in np.arange(n_data_splits):\n",
    "                train = (data_est['splits'] != r)\n",
    "                test = (data_est['splits']==r)\n",
    "                ols_control=ymodel.fit(data_est[feature_name ][(train==True)],\n",
    "                                       data_est[outcome_name][(train==True)]) \n",
    "                prediction = ols_control.predict(data_est[feature_name ][(test==True)])\n",
    "                outcome_hat.extend(prediction)\n",
    "\n",
    "                ols_control=ymodel.fit(data_est[feature_name ][( (train==True) & (data_est[treatment_name]==0) )],\n",
    "                                       data_est[outcome_name][( (train==True) & (data_est[treatment_name]==0) )]) \n",
    "                prediction = ols_control.predict(data_est[feature_name ][(test==True)])\n",
    "                output_baseline_hat.extend(prediction)\n",
    "\n",
    "\n",
    "            y_r2 = predQC.r2(data_est[outcome_name], outcome_hat)\n",
    "            ## 2nd Stage: Estimate OLS of residualized treatments on outcome\n",
    "            ## Interact the residualized treatment with the heterogeneous outcomes    \n",
    "            residual_outcome = data_est[outcome_name] - outcome_hat    \n",
    "\n",
    "            data_for_2nd_stage = pd.DataFrame(data={'y': residual_outcome,\n",
    "                                                    treatment_name:data_est[treatment_name],\n",
    "                                                    'outcome_hat':outcome_hat,\n",
    "                                                    't':residual_treatment_hat[0]})\n",
    "            covar_list = ['t']\n",
    "            h_i = 1\n",
    "            for x in het_feature:\n",
    "                data_for_2nd_stage['t_x'+x] = residual_treatment_hat[h_i]\n",
    "                data_for_2nd_stage[x] = data_est[x]\n",
    "                h_i+=1\n",
    "                covar_list.append('t_x'+x)    \n",
    "\n",
    "\n",
    "            data_for_2nd_stage['half'] = 0\n",
    "            half = np.int(len(data_for_2nd_stage) / 2)\n",
    "            data_for_2nd_stage.loc[data_for_2nd_stage.iloc[-half:].index, 'half' ] = 1\n",
    "\n",
    "            data_for_2nd_stage['cons'] = 1\n",
    "            data_for_2nd_stage['ones'] = 1\n",
    "\n",
    "            data_est_half = {'0': data_for_2nd_stage.loc[data_for_2nd_stage['half']==0], \n",
    "                           '1': data_for_2nd_stage.loc[data_for_2nd_stage['half']==1]}\n",
    "\n",
    "            output_treatment_estimate = []\n",
    "            output_se_hat = []\n",
    "\n",
    "            '''\n",
    "            If the dimensionality of teratment array relative to sample size is less than 20%, then just do an OLS.\n",
    "            But if user is forcing OLS, CVLasso, or Lasso, then let them.\n",
    "            '''        \n",
    "            if aux_dictionary['force_second_stage'] == None:\n",
    "                dim_D = len(het_feature)+1\n",
    "                if (float(dim_D/len(data_est)) <= 0.20):\n",
    "                    approach='OLS'\n",
    "                else:\n",
    "                    approach='CVLasso'\n",
    "            else:\n",
    "                approach = aux_dictionary['force_second_stage']\n",
    "\n",
    "            ols_coef_pd = {}\n",
    "            for test_i,train_i in zip(['0','1'], ['1','0']):            \n",
    "                test_data = data_est_half[test_i]\n",
    "                train_data = data_est_half[train_i]\n",
    "                treatment_estimate,se_estimate, coef_pd = secondstage.second_stage(approach, test_data, train_data, covar_list, het_feature )\n",
    "                output_treatment_estimate.extend(list(treatment_estimate))            \n",
    "                output_se_hat.extend(list(se_estimate))            \n",
    "                ols_coef_pd[test_i] = coef_pd.copy()\n",
    "\n",
    "\n",
    "            other_output = {'coefficients':ols_coef_pd, \n",
    "                            'Treatment outcome metric':t_r2}\n",
    "            ## Output the treatment estimate and propensity scores\n",
    "            return output_treatment_estimate, output_se_hat, that, output_baseline_hat, other_output\n",
    "\n",
    "\n",
    "\n",
    "        ## Approach 2\n",
    "        def SGCT(data_est, \n",
    "                        feature_name, outcome_name, treatment_name,\n",
    "                        het_feature,\n",
    "                        ymodel,tmodel,\n",
    "                       n_data_splits, \n",
    "                     aux_dictionary):                \n",
    "            '''    \n",
    "            aux_dictionary['force_second_stage']    (str) {None, 'OLS','CVLasso', 'Lasso'}\n",
    "            '''\n",
    "            block_splits(data_est, 'splits', n_data_splits)\n",
    "\n",
    "            ## 1st Stage: Predict treatment indicator\n",
    "            that = predict_treatment_indicator(data_est, 'splits', n_data_splits, feature_name,treatment_name, tmodel)\n",
    "\n",
    "            ## 1st Stage: Residualize Treatment Indicator\n",
    "            residual_treatment_hat = data_est[treatment_name] - that \n",
    "\n",
    "            ## 1st Stage: Predict the outcome\n",
    "            outcome_hat = []\n",
    "            output_baseline_hat = []\n",
    "            for r in np.arange(n_data_splits):\n",
    "                train = (data_est['splits'] != r)\n",
    "                test = (data_est['splits']==r)\n",
    "                ols_control=ymodel.fit(data_est[feature_name ][(train==True)],\n",
    "                                       data_est[outcome_name][(train==True)]) \n",
    "                prediction = ols_control.predict(data_est[feature_name ][(test==True)])\n",
    "                outcome_hat.extend(prediction)\n",
    "\n",
    "                ols_control=ymodel.fit(data_est[feature_name ][( (train==True) & (data_est[treatment_name]==0) )],\n",
    "                                       data_est[outcome_name][( (train==True) & (data_est[treatment_name]==0) )]) \n",
    "                prediction = ols_control.predict(data_est[feature_name ][(test==True)])\n",
    "                output_baseline_hat.extend(prediction)\n",
    "\n",
    "            ## 2nd Stage: Estimate OLS of residualized treatments on outcome\n",
    "            ## Interact the residualized treatment with the heterogeneous outcomes    \n",
    "            residual_outcome = data_est[outcome_name] - outcome_hat  \n",
    "\n",
    "            data_for_2nd_stage = pd.DataFrame(data={'y': residual_outcome,\n",
    "                                                    treatment_name:data_est[treatment_name],\n",
    "                                                    'outcome_hat':outcome_hat,\n",
    "                                                    't':residual_treatment_hat})\n",
    "            covar_list = ['t']\n",
    "            h_i = 1\n",
    "            for x in het_feature:\n",
    "                data_for_2nd_stage['t_x'+x] = data_est[x] * residual_treatment_hat\n",
    "                data_for_2nd_stage[x] = data_est[x]\n",
    "                h_i+=1\n",
    "                covar_list.append('t_x'+x)    \n",
    "\n",
    "            ## We want to do ad-hoc feature selection with a Lasso. However, we cannot directly use a Lasso for \n",
    "            ## causal inference because there is feature selection bias (#thatsnothowitworks). Therefore, we \n",
    "            ## run Lasso on one half of the dataset, and use the selected features in an OLS on the other half.\n",
    "            data_for_2nd_stage['half'] = 0\n",
    "            half = np.int(len(data_for_2nd_stage) / 2)\n",
    "            data_for_2nd_stage.loc[data_for_2nd_stage.iloc[-half:].index, 'half' ] = 1\n",
    "\n",
    "            data_for_2nd_stage['cons'] = 1\n",
    "            data_for_2nd_stage['ones'] = 1\n",
    "\n",
    "            data_est_half = {'0': data_for_2nd_stage.loc[data_for_2nd_stage['half']==0], \n",
    "                           '1': data_for_2nd_stage.loc[data_for_2nd_stage['half']==1]}\n",
    "\n",
    "            output_treatment_estimate = []\n",
    "            output_se_hat = []\n",
    "            '''\n",
    "            If the dimensionality of teratment array relative to sample size is less than 20%, then just do an OLS.\n",
    "            But if user is forcing OLS, CVLasso, or Lasso, then let them.\n",
    "            '''        \n",
    "            if aux_dictionary['force_second_stage'] == None:\n",
    "                dim_D = len(het_feature)+1\n",
    "                if (float(dim_D/len(data_est)) <= 0.20):\n",
    "                    approach='OLS'\n",
    "                else:\n",
    "                    approach='CVLasso'\n",
    "            else:\n",
    "                approach = aux_dictionary['force_second_stage']\n",
    "            ols_coef_pd = {}\n",
    "\n",
    "            for test_i,train_i in zip(['0','1'], ['1','0']):            \n",
    "                test_data = data_est_half[test_i]\n",
    "                train_data = data_est_half[train_i]\n",
    "                treatment_estimate,se_estimate, coef_pd = secondstage.second_stage(approach, test_data, train_data, covar_list, het_feature )\n",
    "                output_treatment_estimate.extend(list(treatment_estimate))            \n",
    "                output_se_hat.extend(list(se_estimate))            \n",
    "                ols_coef_pd[test_i] = coef_pd.copy()\n",
    "\n",
    "            other_output = {'coefficients':ols_coef_pd, \n",
    "                            'Treatment outcome metric':t_r2}\n",
    "            ## Output the treatment estimate and propensity scores\n",
    "            return output_treatment_estimate, output_se_hat, that, output_baseline_hat, other_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
