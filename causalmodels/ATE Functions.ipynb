{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference Examples\n",
    "Julian Hsu\n",
    "Date Made: 5 Aug 2021 \n",
    "\n",
    "### Table of Contents with Navigation Links\n",
    "* [Write Causal Models](#Section1)\n",
    "* [Simulate Data](#Section2)\n",
    "* [Bootstrapping Examples](#Section3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.discrete.conditional_models import ConditionalLogit\n",
    "\n",
    "from IPython.display import display    \n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stnomics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "\n",
    "## Write Causal Models\n",
    "Write several functions here for estimate HTE. Each model _must_ do datasplitting.\n",
    "These functions will do a lot of predictions, so try to standardize the prediction models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "\n",
    "## Bring in Simulated Data\n",
    "Pretend we've never seen this data before, and do balance checks between treatment and control \n",
    "\n",
    "For fun, use the Friedman function: https://www.sfu.ca/~ssurjano/fried.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    N = 1000\n",
    "    \n",
    "    cov = [[1.00, 0.08, 0.05, 0.05],\n",
    "           [0.08, 1.00,-0.08,-0.02],\n",
    "           [0.05,-0.08, 1.00,-0.10],\n",
    "           [0.05,-0.02,-0.10, 1.00]]\n",
    "    cov = np.eye(4)\n",
    "    X = np.random.multivariate_normal(np.zeros(4), cov,N)\n",
    "    x1,x2,x3,x4= X[:,0],X[:,1],X[:,2],X[:,3]\n",
    "\n",
    "    treatment_latent = 2*np.sin( np.pi * x4 * x3) + 10*(x2-0.5)**2 - 10*x1\n",
    "    m,s = np.average(treatment_latent), np.std(treatment_latent)\n",
    "\n",
    "    treatment_latent = (treatment_latent - m) / s\n",
    "    \n",
    "    random_t = np.random.normal(0,1,N)\n",
    "    \n",
    "    treatment_latent += random_t\n",
    "    \n",
    "    treatment = np.array( np.exp(treatment_latent) / (1+ np.exp(treatment_latent)) > np.random.uniform(0,1,N) ).astype(np.int32)\n",
    "\n",
    "#     Y = 100 +0.5*x1 - 6*x2 + -2*x4*x1 + 0.5*x1*x2 - 7*(x3+1)**(0.5) + 8/(0.5+x3+x4)\n",
    "    Y = 100 + 10*np.sin( np.pi * x1 * x2) + 20*(x3-0.5)**2 - 10*x4\n",
    "#     GT = np.std(Y)\n",
    "    random_y = np.random.normal(0,1,N)\n",
    "\n",
    "    GT = 5\n",
    "    Y += np.random.normal(1,2,N)\n",
    "    Y += GT*(treatment==1) \n",
    "    \n",
    "    df_est = pd.DataFrame({'x1':x1, 'x2':x2,'x3':x3,'x4':x4,'treatment':treatment, 'Y':Y, 'GT':GT} )\n",
    "    df_est['x1_2'] = df_est['x1'].pow(2)\n",
    "    df_est['x2_2'] = df_est['x2'].pow(2)\n",
    "    df_est['x3_2'] = df_est['x3'].pow(2)\n",
    "    df_est['x4_2'] = df_est['x4'].pow(2)    \n",
    "    return df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_iter = 500\n",
    "## treatment prediction models\n",
    "t_models = {}\n",
    "t_models['LogitCV'] = LogisticRegressionCV(cv=5, random_state=27, n_jobs=-1)\n",
    "t_models['logit'] = LogisticRegression(penalty='l2',solver='lbfgs', C=1, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L1_C2'] = LogisticRegression(penalty='l1',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L2_C5'] = LogisticRegression(penalty='l2',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['rf_md10'] = RandomForestClassifier(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "t_models['rf_md3'] = RandomForestClassifier(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "t_models['nn'] = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1,max_iter=model_max_iter)\n",
    "## outcome prediction models\n",
    "y_models = {}\n",
    "y_models['LassoCV'] = LassoCV(cv=5, n_jobs=-1, normalize=True, random_state=27)\n",
    "y_models['ols'] = LinearRegression()\n",
    "y_models['lasso_a2'] = Lasso(alpha=2,max_iter=model_max_iter)\n",
    "y_models['ridge_a2'] = Ridge(alpha=2,max_iter=model_max_iter)\n",
    "y_models['rf_md10'] = RandomForestRegressor(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "y_models['rf_md3'] = RandomForestRegressor(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "y_models['nn'] = MLPRegressor(alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1, max_iter=model_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_splits = 4\n",
    "aux_dictionary = {'n_bins': 2, 'n_trees':2, 'max_depth':2, \n",
    "                  'upper':0.999, 'lower':0.001,\n",
    "                  'subsample_ratio':0.5,\n",
    "                 'bootstrapreps':10 }\n",
    "bootstrap_number = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "\n",
    "feature_list = [x for x in df.columns if 'x' in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ate' has no attribute 'prop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-178052f362a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ate' has no attribute 'prop'"
     ]
    }
   ],
   "source": [
    "st.ate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'propbinning_main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9aa15757b494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ols = st.ate.propbinning(df, \n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0;34m'splits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'treatment'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0my_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LassoCV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogitCV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                n_data_splits, aux_dictionary )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/stnomics.py\u001b[0m in \u001b[0;36mpropbinning\u001b[0;34m(data_est, split_name, feature_name, outcome_name, treatment_name, ymodel, tmodel, n_data_splits, aux_dictionary)\u001b[0m\n\u001b[1;32m    588\u001b[0m                    \u001b[0mn_data_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                    aux_dictionary):\n\u001b[0;32m--> 590\u001b[0;31m         main_result = propbinning_main(data_est, \n\u001b[0m\u001b[1;32m    591\u001b[0m                     \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mymodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'propbinning_main' is not defined"
     ]
    }
   ],
   "source": [
    "ols = st.ate.propbinning(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ols = st.ate.ols_vanilla(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "pbin = propbinning(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "plm = dml_plm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "irm = dml_irm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "ip = ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "ip_wls = ipw_wls(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols_vanilla  ATE 4.297[0.448] \n",
      "ols_vanilla  ATT 4.297[0.448] \n",
      "propbinning  ATE 4.456[0.597] \n",
      "propbinning  ATT 4.456[0.597] \n",
      "dml_plm  ATE 4.211[0.445] \n",
      "dml_plm  ATT 4.211[0.445] \n",
      "dml_irm  ATE 4.137[0.465] \n",
      "dml_irm  ATT 4.408[0.468] \n",
      "ipw  ATE -11.589[18.300] \n",
      "ipw  ATT -11.589[18.300] \n",
      "ipw_wls  ATE 4.822[2.494] \n",
      "ipw_wls  ATT 3.908[2.522] \n"
     ]
    }
   ],
   "source": [
    "for n,r in zip([ols_vanilla, propbinning, dml_plm, dml_irm, ipw, ipw_wls], [ols, pbin, plm, irm, ip, ip_wls]):\n",
    "    print('{0}  ATE {1:5.3f}[{2:5.3f}] '.format(n.__name__, r['ATE TE'], r['ATE SE']))\n",
    "    print('{0}  ATT {1:5.3f}[{2:5.3f}] '.format(n.__name__, r['ATT TE'], r['ATT SE']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
