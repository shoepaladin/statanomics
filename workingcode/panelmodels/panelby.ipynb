{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243a43a9",
   "metadata": {},
   "source": [
    "# panelby\n",
    "Julian Hsu\n",
    "This is our package for panel models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "348a8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from IPython.display import display    \n",
    "\n",
    "import scipy.stats \n",
    "from sklearn.linear_model import ElasticNet\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3f304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1fa4340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the univeral function that calls all the different SC models coded up below.\n",
    "## It will also call functions used for SC model validation\n",
    "\n",
    "class sc:\n",
    "    def sc_model(model_name='adh',\n",
    "                data=None,\n",
    "                data_dict= {'treatment':None, 'date':None, 'post':None, 'unitid':None, 'outcome':None},\n",
    "                pre_process_data=None,\n",
    "                pre_treatment_window=None):\n",
    "        ## First pre-process the data if possible.\n",
    "        if pre_process_data==None:\n",
    "            pre_process_data = dgp.clean_and_input_data(dataset=data,\n",
    "                                                        treatment=data_dict['treatment'],\n",
    "                                                        unit_id=data_dict['unitid'],\n",
    "                                                        date=data_dict['date'],\n",
    "                                                        post=data_dict['post'],\n",
    "                                                        outcome=data_dict['outcome'])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ## Second calculate the pre-treatment-window that can be useful for placebo tests\n",
    "        pre_treatment_window = dgp.determine_pre_treatment_window(ci_data_output=pre_process_data,\n",
    "                                                                 pre_treatment_window=pre_treatment_window)\n",
    "        \n",
    "        \n",
    "        ## Finally, call an SC model.\n",
    "        if model_name=='adh':\n",
    "            print('Using ADH')\n",
    "            sc_est = adh.predict_omega(pre_process_data['T_pre'], \n",
    "                                    pre_process_data['C_pre'], \n",
    "                                    pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'], \n",
    "                                             pre_process_data['T_pst'],\n",
    "                                             pre_process_data['C_pre'], \n",
    "                                             pre_process_data['C_pst'],\n",
    "                                np.zeros(pre_process_data['T_pst'].shape[1]), np.array(sc_est['omega']))\n",
    "            sc_est['mu'] = np.zeros( pre_process_data['T_pre'].shape[1] )\n",
    "            \n",
    "        elif model_name=='di':\n",
    "            print('Using DI')\n",
    "            w=alpha_lambda.get_alpha_lambda(sc_dict['C_pre'])\n",
    "            alpha_lambda_to_use = alpha_lambda.alpha_lambda_transform(w.x)\n",
    "            ## Take the alpha and lambda values, and estimate mu and omega\n",
    "            sc_est = di.predict_mu_omega(pre_process_data['T_pre'], \n",
    "                                         pre_process_data['C_pre'], alpha_lambda_to_use, \n",
    "                                         pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'], \n",
    "                                            pre_process_data['T_pst'],\n",
    "                                            pre_process_data['C_pre'], \n",
    "                                            pre_process_data['C_pst'],\n",
    "                                            sc_est['mu'],sc_est['omega'])\n",
    "            \n",
    "        elif model_name=='cl':\n",
    "            print('Using CL')\n",
    "            sc_est = cl.predict_mu_omega(pre_process_data['T_pre'],\n",
    "                                      pre_process_data['C_pre'], \n",
    "                                      pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'],\n",
    "                                            pre_process_data['T_pst'],\n",
    "                                            pre_process_data['C_pre'], \n",
    "                                            pre_process_data['C_pst'],\n",
    "                                            sc_est['mu'], sc_est['omega']) \n",
    "        else:\n",
    "            print('SC Model name not supported. \\n [adh,di,cl] are supported models.')\n",
    "        \n",
    "        ## Output measures of fit pre-treatment (training), pre_treatment (test), and post-treatment\n",
    "        sc_validation = sc.sc_validation(treatment_pre=pre_process_data['T_pre'], \n",
    "                     treatment_pst=pre_process_data['T_pst'],\n",
    "                     control_pre=  pre_process_data['C_pre'],\n",
    "                     control_pst=  pre_process_data['C_pst'], \n",
    "                     mu=  sc_est['mu'],\n",
    "                     omega=sc_est['omega'],\n",
    "                     pre_treatment_window=pre_treatment_window)\n",
    "        return {**sc_output, **sc_validation}\n",
    "\n",
    "\n",
    "    '''\n",
    "    Create a function that evaluates how well the SC model does at matching the:\n",
    "    1. pre-treatment data used for training;\n",
    "    2. pre-treatment data used for testing; and\n",
    "    3. the post-treatment data.\n",
    "    \n",
    "    Calculate metrics of fit and compare pre-treatment and post-treatment metrics.\n",
    "    '''\n",
    "    def sc_validation(treatment_pre, treatment_pst, control_pre, control_pst, \n",
    "                                      mu,omega,\n",
    "                                     pre_treatment_window):\n",
    "        ## Re-combine the observed treatment and control outcomes\n",
    "        y_treat_obs = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        y_control_obs = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        ## Estimate the counterfactual outcome of the treatment group\n",
    "        y_treat_hat = mu + np.dot(y_control_obs, omega.T)\n",
    "\n",
    "        from sklearn.metrics import mean_absolute_percentage_error\n",
    "        def comparison_over_windows(x,y,\n",
    "                                    pre_treatment_window,\n",
    "                                   metric_func, index_name):\n",
    "            x_pre_train = x[0:pre_treatment_window[0]]\n",
    "            y_pre_train = y[0:pre_treatment_window[0]]\n",
    "            x_pre_test = x[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "            y_pre_test = y[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "            x_pst_test = x[-1*(pre_treatment_window[0]+pre_treatment_window[1]):]\n",
    "            y_pst_test = y[-1*(pre_treatment_window[0]+pre_treatment_window[1]):]\n",
    "            test_pre_train = metric_func(x_pre_train, y_pre_train)\n",
    "            test_pre_test  = metric_func(x_pre_test,  y_pre_test)\n",
    "            test_pst_test  = metric_func(x_pst_test,  y_pst_test)\n",
    "            \n",
    "            return pd.DataFrame(index=[index_name], data={'test_pre_train':test_pre_train,\n",
    "                   'test_pre_test':test_pre_test,\n",
    "                   'tesT_pst_test':test_pst_test})\n",
    "            \n",
    "        ## Compare the predicted treatment with the observed control\n",
    "#         treat_hat_control_obs = comparison_over_windows(y_treat_hat, y_control_obs,\n",
    "#                                                    pre_treatment_window,\n",
    "#                                                    mean_absolute_percentage_error,'mape_vs_control_obs')\n",
    "        ## Compare the predicted treatment with the observed treatment\n",
    "        treat_hat_treat_obs = comparison_over_windows(y_treat_hat, y_treat_obs,\n",
    "                                                   pre_treatment_window,\n",
    "                                                   mean_absolute_percentage_error,'mape_vs_treat_obs')\n",
    "        return treat_hat_treat_obs\n",
    "    \n",
    "    \n",
    "## DGP and functions to determine what types of SC models to do, and calculate primatives for SC models\n",
    "class dgp:    \n",
    "    def determine_pre_treatment_window(ci_data_output=None,\n",
    "                                      pre_treatment_window=None):\n",
    "        if pre_treatment_window ==None:\n",
    "            pre_treatment_len = ci_data_output['C_pre'].shape[0]\n",
    "            pre_t0 = int( 0.75*pre_treatment_len )\n",
    "            if pre_t0 < 1:\n",
    "                pre_t0=1\n",
    "            else:\n",
    "                pass            \n",
    "            pre_t1 = pre_treatment_len - pre_t0\n",
    "            pre_treatment_window = [pre_t0, pre_t1]\n",
    "        else:\n",
    "            pass\n",
    "        return pre_treatment_window \n",
    "    \n",
    "    def clean_and_input_data(dataset=None, \n",
    "                             treatment='treated_unit', \n",
    "                             unit_id = 'unitid',\n",
    "                             date='T',\n",
    "                             post='post', outcome='Y'):\n",
    "        \n",
    "        C_pre = dataset.loc[(dataset[treatment]==0) & (dataset[post]==0)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        C_pst = dataset.loc[(dataset[treatment]==0) & (dataset[post]==1)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pre = dataset.loc[(dataset[treatment]==1) & (dataset[post]==0)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pst = dataset.loc[(dataset[treatment]==1) & (dataset[post]==1)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        return {'C_pre':C_pre, 'C_pst':C_pst, 'T_pre':T_pre, 'T_pst':T_pst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6a44a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doudchenko Imbens, (2016) Model\n",
    "class di:\n",
    "    def estimate_mu_omega(treatment_pre, control_pre, alpha_lambda_0):\n",
    "        alpha_0, lambda_0 = alpha_lambda_0[0], alpha_lambda_0[1]\n",
    "        elnet = ElasticNet(random_state=2736, alpha=alpha_0, l1_ratio=lambda_0)\n",
    "        elnet.fit(control_pre, treatment_pre )\n",
    "        ## Output interpretable weights\n",
    "        try:\n",
    "            df_weights= pd.DataFrame(data=zip(treatment_pre.columns,\n",
    "                                              elnet.coef_.T\n",
    "                                             ))\n",
    "        except:\n",
    "            df_weights = pd.DataFrame(index=np.arange(len(elnet.coef_)), \n",
    "                         data=elnet.coef_.T)        \n",
    "        return {'mu': elnet.intercept_, 'omega': elnet.coef_, 'weights':df_weights, 'full':elnet}\n",
    "\n",
    "    def predict_mu_omega(treatment_pre, control_pre, alpha_lambda_0, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the DI model\n",
    "        holdout_dict = di.estimate_mu_omega(treatment_holdout, control_holdout, alpha_lambda_0)\n",
    "        if treatment_pre.shape[1]==1:\n",
    "            holdout_dict['omega'] = np.array([holdout_dict['omega']])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "        diff_holdout = treatment_holdout       -\\\n",
    "            np.dot(control_holdout, holdout_dict['omega'].T)+holdout_dict['mu']        \n",
    "        diff_nonholdout = treatment_nonholdout -\\\n",
    "            np.dot(control_nonholdout, holdout_dict['omega'].T)+holdout_dict['mu']\n",
    "\n",
    "        diff_nonholdout_mse = (diff_nonholdout**2).mean()\n",
    "        diff_holdout_mse = (diff_holdout**2).mean()\n",
    "        return {'mu':     holdout_dict['mu'],\n",
    "               'omega':   holdout_dict['omega'],\n",
    "               'weights': holdout_dict['weights'],\n",
    "               'full':    holdout_dict['full'],\n",
    "               'mse_holdout': diff_holdout_mse,\n",
    "               'mse_nonholdout':diff_nonholdout_mse}\n",
    "\n",
    "    \n",
    "    def sc_style_results(treatment_pre, treatment_pst, control_pre, control_pst, mu,omega):\n",
    "        ## Do some normalization of the omega input\n",
    "        if len(omega.shape) > 2:\n",
    "            omega = omega.reshape(omega.shape[-2],omega.shape[-1])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        final_X = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        control_X = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        control_df = mu + pd.DataFrame(data=np.dot(control_X, omega.T), columns=[ l+'_est' for l in final_X.columns ])\n",
    "        control_df.index = final_X.index\n",
    "        \n",
    "        output_df = control_df.join(final_X)\n",
    "        \n",
    "        treatment_periods = -1*len(treatment_pst)\n",
    "        atet_df = pd.DataFrame()\n",
    "        for c in [l for l in output_df.columns if '_est' not in l]:\n",
    "            diff = output_df[c][treatment_periods:] - output_df[c+'_est'][treatment_periods:]\n",
    "            atet_df[c] = diff\n",
    "        \n",
    "        return {'atet': atet_df , 'predict_est':output_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5ca4ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here code up the functions that we will try to minimize over\n",
    "class alpha_lambda:\n",
    "    def diff(y_t,y_c, mu_x, omega_x):\n",
    "        return y_t - mu_x - np.dot(y_c,omega_x)\n",
    "\n",
    "    def alpha_lambda_transform(alpha_lambda_raw_):\n",
    "        ## Alpha is strictly greater than zero\n",
    "        ## lambda exists between 0 and 1\n",
    "        return np.exp(alpha_lambda_raw_[0]/1000), np.exp(alpha_lambda_raw_[1])/(1+np.exp(alpha_lambda_raw_[1])), \n",
    "    def alpha_lambda_diff(alpha_lambda_raw_, control_pre):\n",
    "        ## Transform the inputted alpha,lambda values \n",
    "        alpha_lambda_t = alpha_lambda.alpha_lambda_transform(alpha_lambda_raw_)\n",
    "        difference_array = []\n",
    "        ## Pick one control unit as the pretend treatment unit\n",
    "        for u in control_pre.columns:\n",
    "            control_pre_placebo_treat = control_pre[u]\n",
    "            control_pre_placebo_cntrl = control_pre[ [l for l in control_pre.columns if l !=u] ]\n",
    "\n",
    "            ## Estimate mu and lambda with that control unit\n",
    "            control_pre_placebo_w = di.estimate_mu_omega(control_pre_placebo_treat,\n",
    "                             control_pre_placebo_cntrl,\n",
    "                             alpha_lambda_t)\n",
    "            ## Estimate the difference\n",
    "            d = alpha_lambda.diff(control_pre_placebo_treat, \n",
    "                 control_pre_placebo_cntrl, \n",
    "                 control_pre_placebo_w['mu'],\n",
    "                 control_pre_placebo_w['omega'])\n",
    "            difference_array.append(d)\n",
    "        ## Estimate the difference across all the control units\n",
    "        d_mean = np.mean(difference_array)\n",
    "        return d_mean\n",
    "    def get_alpha_lambda(control_pre_input):\n",
    "        ## Initialize at a given point\n",
    "        weights = minimize(partial(alpha_lambda.alpha_lambda_diff, control_pre=control_pre_input),\n",
    "                             np.array([10.15,0.5]),\n",
    "                           method='BFGS',\n",
    "                          options={'maxiter':5000, 'gtol': 1e-07, 'disp':False})\n",
    "        return weights\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "488a1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constrained Lasso Model\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class cl:\n",
    "    def cl_obj(params, y,x) -> float:\n",
    "        return np.mean(  (y - params[0] - np.dot(x,params[1:]))**2)\n",
    "    \n",
    "    def predict_mu_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['mu'] = []\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        if treatment_pre.shape[1] > 1:\n",
    "            for t in treatment_pre.columns:\n",
    "                t_dict = cl.get_mu_omega(treatment_holdout[t], control_holdout)\n",
    "                ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "                diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict['omega'].T)+t_dict['mu']\n",
    "                diff_h_mse = (diff_h**2).mean()\n",
    "                diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict['omega'].T)+t_dict['mu']\n",
    "                diff_nh_mse = (diff_nh**2).mean()\n",
    "        \n",
    "                holdout_dict['mu'].append(t_dict['mu'])\n",
    "                holdout_dict['omega'].append(t_dict['omega'])\n",
    "                holdout_dict['weights'].append(t_dict['weights'])\n",
    "                diff_holdout_mse.append(diff_h_mse)\n",
    "                diff_nonholdout_mse.append(diff_nh_mse)\n",
    "        else:\n",
    "            \n",
    "            t_dict = cl.get_mu_omega(treatment_holdout.values.flatten(), control_holdout)\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            t_dict['omega'] = np.array([t_dict['omega']])\n",
    "            diff_h= treatment_holdout       - np.dot(control_holdout, t_dict['omega'].T)+t_dict['mu']\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout - np.dot(control_nonholdout, t_dict['omega'].T)+t_dict['mu']\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['mu'].append(t_dict['mu'])\n",
    "            holdout_dict['omega'].append(t_dict['omega'])\n",
    "            holdout_dict['weights'].append(t_dict['weights'])\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)            \n",
    "                    \n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        if len(holdout_dict['omega'].shape) > 2:\n",
    "            holdout_dict['omega'] = holdout_dict['omega'].reshape(holdout_dict['omega'].shape[-2],holdout_dict['omega'].shape[-1])\n",
    "        else:\n",
    "            pass        \n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "\n",
    "        return holdout_dict\n",
    "\n",
    "\n",
    "    def get_mu_omega(treatment_pre_input, control_pre_input):\n",
    "        n = control_pre_input.shape[1]\n",
    "        initialx = np.ones(n+1)/1\n",
    "        ## Initialize at a given point\n",
    "        weights = fmin_slsqp(partial(cl.cl_obj, y=treatment_pre_input,\n",
    "                                  x=control_pre_input),\n",
    "                             initialx,\n",
    "                             f_ieqcons=lambda x: 1-np.sum(np.abs(x[1:])),\n",
    "                         iter=50000, \n",
    "                         disp=False)\n",
    "        mu, omega = weights[0], weights[1:]\n",
    "        return {'mu':mu, 'omega':omega, 'weights':weights}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2d4eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abadie, Diamond, Hainmueller (2010) model\n",
    "## Also code up the ADH weights\n",
    "## Abadie/Diamond/Hainmueller    \n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class adh:\n",
    "    ## Define loss function\n",
    "    def loss_w(W, X, y) -> float:\n",
    "        return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "    def get_w(X, y):\n",
    "        ## Initialize at sample average with some noise\n",
    "        w_start = [1/X.shape[1]]*X.shape[1]\n",
    "    #     w_start = np.ones(X.shape[1])\n",
    "\n",
    "        weights = fmin_slsqp(partial(adh.loss_w, X=X, y=y),\n",
    "                             np.array(w_start),\n",
    "                             f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                             iter=50000, \n",
    "                             bounds=[(0.0, 1.0)]*len(w_start),\n",
    "                             disp=False)\n",
    "        return weights   \n",
    "    \n",
    "    def predict_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        if treatment_pre.shape[1] > 1:\n",
    "            for t in treatment_pre.columns:\n",
    "                t_dict = adh.get_w(control_holdout,treatment_holdout[t])\n",
    "                ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "                diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict.T)\n",
    "                diff_h_mse = (diff_h**2).mean()\n",
    "                diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict.T)\n",
    "                diff_nh_mse = (diff_nh**2).mean()\n",
    "        \n",
    "                holdout_dict['omega'].append(t_dict)\n",
    "                holdout_dict['weights'].append(t_dict)\n",
    "                diff_holdout_mse.append(diff_h_mse)\n",
    "                diff_nonholdout_mse.append(diff_nh_mse)\n",
    "        else:\n",
    "            t_dict = adh.get_w(control_holdout,treatment_holdout.values.flatten())\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            diff_h= treatment_holdout       - np.dot(control_holdout, np.array([t_dict]).T)\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout - np.dot(control_nonholdout, np.array([t_dict]).T)\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['omega'].append(t_dict)\n",
    "            holdout_dict['weights'].append(t_dict)\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)            \n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "        \n",
    "        return holdout_dict    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5f16606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conformal Inference to do inference for the SC models\n",
    "import itertools\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "rng.choice(10, size=10, replace=False)\n",
    "\n",
    "\n",
    "class conformal_inf:\n",
    "    def scrambled_residual(counterfactual, actual, \n",
    "                       scrambled_order,\n",
    "                      treatment_window):\n",
    "        '''\n",
    "        counterfactual   array of counterfactual estimates that are assumed to be ordered sequentially\n",
    "        actual           ``'' for actual values\n",
    "        scrambled_order  integer array that tells me how to scramble these\n",
    "        treatment_window list of two integers for the number of pre-treatment and post-treatment units\n",
    "        '''\n",
    "        counterfactual_ = counterfactual[scrambled_order][-1*treatment_window[1]:]\n",
    "        actual_         = actual[scrambled_order][-1*treatment_window[1]:]    \n",
    "        return actual_ - counterfactual_\n",
    "    \n",
    "    def test_statS(q, treatment_window, residual):\n",
    "        normed = np.sum(  np.power(np.abs(residual), q)  )\n",
    "        return np.power( treatment_window[1]**(-0.5)*normed , 1/q)    \n",
    "\n",
    "    def pvalue_calc(counterfactual=None,\n",
    "                    actual=None, \n",
    "                    permutation_list=None,\n",
    "                   treatment_window=None,\n",
    "                   h0 = 0):\n",
    "        control_pst = counterfactual[-1*treatment_window[1]:]\n",
    "        actual_pst  = actual[-1*treatment_window[1]:] \n",
    "        actual_pst -= h0\n",
    "\n",
    "        ## Calculate the residual\n",
    "        residual_initial = np.abs(actual_pst - control_pst)         \n",
    "        S_q = conformal_inf.test_statS(1, treatment_window, residual_initial)\n",
    "\n",
    "        ## Now do a whole bunch of treatment time scrambles\n",
    "        ## We're going to permute over all time-based permutations\n",
    "        ## Adjust the actual by the null hypothesis \n",
    "        treat_ = actual[:]\n",
    "        treat_[-1*treatment_window[1]:] -= h0\n",
    "        full_residual = np.abs(treat_ - counterfactual)\n",
    "        S_q_pi = []\n",
    "        for r in permutation_list:\n",
    "            scrambled_dates = np.array(list(r))              \n",
    "            residual_ = full_residual[scrambled_dates][-1*treatment_window[1]:]\n",
    "            S_q_pi.append(  conformal_inf.test_statS(1, treatment_window, residual_ )  )\n",
    "        p_value = 1 - np.average( (np.array(S_q_pi) < S_q ) )\n",
    "        return p_value\n",
    "    \n",
    "    def ci_calc(y_hat=None,\n",
    "               y_act=None,\n",
    "               theta_grid=None,\n",
    "                permutation_list_ci = None,\n",
    "                treatment_window_ci =None,\n",
    "               alpha=0.05):\n",
    "        pv_grid = []\n",
    "        for t in theta_grid:\n",
    "            pv = conformal_inf.pvalue_calc(counterfactual=y_hat.copy(),\n",
    "                        actual=y_act.copy(), \n",
    "                            permutation_list = permutation_list_ci,\n",
    "                           treatment_window = treatment_window_ci,\n",
    "                                 h0=t)\n",
    "            pv_grid.append(pv)   \n",
    "        ci_list = [ theta_grid[i] for i in range(len(pv_grid)) if pv_grid[i] < alpha ]\n",
    "        return {'theta_list':theta_grid, 'pvalue_list':pv_grid, 'ci_list':ci_list,\n",
    "               'ci_interval':[np.min(ci_list), np.max(ci_list)]\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83611126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc6ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd64bad",
   "metadata": {},
   "source": [
    "Test these functions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a615d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "N = 100\n",
    "initial = np.random.uniform(0,1, N)\n",
    "df = pd.DataFrame(data={'y':initial,\n",
    "                  'unit_id':np.arange(N),\n",
    "                       'time':np.zeros(N).astype(int)})\n",
    "for t in range(10):\n",
    "    entry = df.iloc[-1*N:]\n",
    "    entry['y'] = entry['y']*0.80 + np.random.normal(0,0.5,N)*0.20\n",
    "    entry.loc[[True]*N,'time'] = t\n",
    "    df = pd.concat([df,entry])\n",
    "df['treated']        = df['unit_id'].isin([0,1,2])\n",
    "df['post'] = (df['time'] > 7)\n",
    "df['W'] =     df['treated']*    df['post']\n",
    "df['unit_id'] = df['unit_id'].apply(str)\n",
    "df.loc[df['W']==True, 'y'] += 3\n",
    "## Clean data\n",
    "\n",
    "sc_dict = dgp.clean_and_input_data(dataset=df,\n",
    "                                   treatment='treated',\n",
    "                                   unit_id='unit_id',\n",
    "                                   date='time',\n",
    "                                   post='post',\n",
    "                                  outcome='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "179c9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_window_pre_treatment = dgp.determine_pre_treatment_window(ci_data_output=sc_dict, pre_treatment_window=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9ad24311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'atet':              0\n",
       " time          \n",
       " 8     2.686007\n",
       " 9     2.757463,\n",
       " 'predict_est':          0_est         0\n",
       " time                    \n",
       " 0     0.174317  0.050716\n",
       " 1     0.174317  0.071506\n",
       " 2     0.174317  0.148940\n",
       " 3     0.174317  0.281061\n",
       " 4     0.174317  0.217515\n",
       " 5     0.174317  0.276164\n",
       " 6     0.174317  0.062582\n",
       " 7     0.174317 -0.214984\n",
       " 8     0.174317  2.860324\n",
       " 9     0.174317  2.931779,\n",
       " 'test_pre_train': mape_vs_treat_obs    0.481477\n",
       " Name: test_pre_train, dtype: float64,\n",
       " 'test_pre_test': mape_vs_treat_obs    1.437141\n",
       " Name: test_pre_test, dtype: float64,\n",
       " 'tesT_pst_test': mape_vs_treat_obs    4.461466\n",
       " Name: tesT_pst_test, dtype: float64}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.sc_model(model_name='di',\n",
    "        data=df,\n",
    "        data_dict={'treatment': 'treated',\n",
    "                  'date':'time',\n",
    "                  'post':'post',\n",
    "                  'unitid':'unit_id',\n",
    "                  'outcome':'y'},\n",
    "        pre_process_data=None,\n",
    "        pre_treatment_window=None)\n",
    "\n",
    "\n",
    "# ## Figure out the alpha and lambda values\n",
    "# w=alpha_lambda.get_alpha_lambda(sc_dict['C_pre'])\n",
    "# alpha_lambda_to_use = alpha_lambda.alpha_lambda_transform(w.x)\n",
    "# ## Take the alpha and lambda values, and estimate mu and omega\n",
    "# di_est = di.predict_mu_omega(sc_dict['T_pre'], sc_dict['C_pre'], alpha_lambda_to_use, \n",
    "#                              treatment_window_pre_treatment)\n",
    "# di_output = di.sc_style_results(sc_dict['T_pre'], sc_dict['T_pst'],\n",
    "#                     sc_dict['C_pre'], sc_dict['C_pst'],\n",
    "#                         di_est['mu'],di_est['omega'])\n",
    "# di_validation = sc.sc_validation(treatment_pre=sc_dict['T_pre'], \n",
    "#                  treatment_pst=sc_dict['T_pst'],\n",
    "#                  control_pre=sc_dict['C_pre'],\n",
    "#                  control_pst=sc_dict['C_pst'], \n",
    "#                  mu=di_est['mu'],\n",
    "#                  omega=di_est['omega'],\n",
    "#                  pre_treatment_window=treatment_window_pre_treatment)\n",
    "\n",
    "# ak7 = cl.predict_mu_omega(sc_dict['T_pre'], sc_dict['C_pre'], treatment_window_pre_treatment)\n",
    "# cl_output = di.sc_style_results(sc_dict['T_pre'], sc_dict['T_pst'],\n",
    "#                     sc_dict['C_pre'], sc_dict['C_pst'],\n",
    "#                     ak7['mu'], ak7['omega'])\n",
    "# sc_validation = sc.sc_validation(treatment_pre=sc_dict['T_pre'], \n",
    "#                  treatment_pst=sc_dict['T_pst'],\n",
    "#                  control_pre=sc_dict['C_pre'],\n",
    "#                  control_pst=sc_dict['C_pst'], \n",
    "#                  mu=ak7['mu'],\n",
    "#                  omega=ak7['omega'],\n",
    "#                  pre_treatment_window=treatment_window_pre_treatment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c7584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
