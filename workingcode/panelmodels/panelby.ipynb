{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243a43a9",
   "metadata": {},
   "source": [
    "# panelby\n",
    "Julian Hsu\n",
    "This is our package for panel models. We use our own written synthetic control and a diff-in-diff model using `statsmodels`.\n",
    "\n",
    "**todolist**\n",
    "1. Correct p-value calculation for SC models\n",
    "2. Output aggregate ATET and p-value for SC models\n",
    "3. Code up DiD Model\n",
    "    1. OLS model for TWFE\n",
    "    2. placebo OLS model with event study\n",
    "    3. Output F-test, t-tests, and graphical evidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "348a8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from IPython.display import display    \n",
    "\n",
    "import scipy.stats \n",
    "from sklearn.linear_model import ElasticNet\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3f304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c59307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1fa4340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the univeral function that calls all the different SC models coded up below.\n",
    "## It will also call functions used for SC model validation\n",
    "\n",
    "class sc:\n",
    "    def sc_model(model_name='adh',\n",
    "                data=None,\n",
    "                data_dict= {'treatment':None, 'date':None, 'post':None, 'unitid':None, 'outcome':None},\n",
    "                pre_process_data=None,\n",
    "                pre_treatment_window=None):\n",
    "        ## First pre-process the data if possible.\n",
    "        if pre_process_data==None:\n",
    "            pre_process_data = dgp.clean_and_input_data(dataset=data,\n",
    "                                                        treatment=data_dict['treatment'],\n",
    "                                                        unit_id=data_dict['unitid'],\n",
    "                                                        date=data_dict['date'],\n",
    "                                                        post=data_dict['post'],\n",
    "                                                        outcome=data_dict['outcome'])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ## Second calculate the pre-treatment-window that can be useful for placebo tests\n",
    "        pre_treatment_window = dgp.determine_pre_treatment_window(ci_data_output=pre_process_data,\n",
    "                                                                 pre_treatment_window=pre_treatment_window)\n",
    "        \n",
    "        \n",
    "        ## Finally, call an SC model.\n",
    "        if model_name=='adh':\n",
    "            print('Using ADH')\n",
    "            sc_est = adh.predict_omega(pre_process_data['T_pre'], \n",
    "                                    pre_process_data['C_pre'], \n",
    "                                    pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'], \n",
    "                                             pre_process_data['T_pst'],\n",
    "                                             pre_process_data['C_pre'], \n",
    "                                             pre_process_data['C_pst'],\n",
    "                                np.zeros(pre_process_data['T_pst'].shape[1]), np.array(sc_est['omega']))\n",
    "            sc_est['mu'] = np.zeros( pre_process_data['T_pre'].shape[1] )\n",
    "            \n",
    "        elif model_name=='di':\n",
    "            print('Using DI')\n",
    "            w=alpha_lambda.get_alpha_lambda(sc_dict['C_pre'])\n",
    "            alpha_lambda_to_use = alpha_lambda.alpha_lambda_transform(w.x)\n",
    "            ## Take the alpha and lambda values, and estimate mu and omega\n",
    "            sc_est = di.predict_mu_omega(pre_process_data['T_pre'], \n",
    "                                         pre_process_data['C_pre'], alpha_lambda_to_use, \n",
    "                                         pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'], \n",
    "                                            pre_process_data['T_pst'],\n",
    "                                            pre_process_data['C_pre'], \n",
    "                                            pre_process_data['C_pst'],\n",
    "                                            sc_est['mu'],sc_est['omega'])\n",
    "            \n",
    "        elif model_name=='cl':\n",
    "            print('Using CL')\n",
    "            sc_est = cl.predict_mu_omega(pre_process_data['T_pre'],\n",
    "                                      pre_process_data['C_pre'], \n",
    "                                      pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'],\n",
    "                                            pre_process_data['T_pst'],\n",
    "                                            pre_process_data['C_pre'], \n",
    "                                            pre_process_data['C_pst'],\n",
    "                                            sc_est['mu'], sc_est['omega']) \n",
    "        else:\n",
    "            print('SC Model name not supported. \\n [adh,di,cl] are supported models.')\n",
    "        \n",
    "        ## Output measures of fit pre-treatment (training), pre_treatment (test), and post-treatment\n",
    "        sc_validation = sc.sc_validation(treatment_pre=pre_process_data['T_pre'], \n",
    "                     treatment_pst=pre_process_data['T_pst'],\n",
    "                     control_pre=  pre_process_data['C_pre'],\n",
    "                     control_pst=  pre_process_data['C_pst'], \n",
    "                     mu=  sc_est['mu'],\n",
    "                     omega=sc_est['omega'],\n",
    "                     pre_treatment_window=pre_treatment_window)\n",
    "        \n",
    "        ## Improve on this by calling for inference results\n",
    "        sc_df_results = sc.collect_sc_outputs(sc_output = sc_output,\n",
    "                           pre_process_data=pre_process_data,\n",
    "                       theta_grid = np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=pre_treatment_window, alpha = 0.05)\n",
    "        \n",
    "        return {**sc_output, 'results_df':sc_df_results}\n",
    "\n",
    "\n",
    "    '''\n",
    "    Create a function that evaluates how well the SC model does at matching the:\n",
    "    1. pre-treatment data used for training;\n",
    "    2. pre-treatment data used for testing; and\n",
    "    3. the post-treatment data.\n",
    "    \n",
    "    Calculate metrics of fit and compare pre-treatment and post-treatment metrics.\n",
    "    '''\n",
    "    def sc_validation(treatment_pre, treatment_pst, control_pre, control_pst, \n",
    "                                      mu,omega,\n",
    "                                     pre_treatment_window):\n",
    "        ## Re-combine the observed treatment and control outcomes\n",
    "        y_treat_obs = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        y_control_obs = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        ## Estimate the counterfactual outcome of the treatment group\n",
    "        y_treat_hat = mu + np.dot(y_control_obs, omega.T)\n",
    "\n",
    "        from sklearn.metrics import mean_absolute_percentage_error\n",
    "        def comparison_over_windows(x,y,\n",
    "                                    pre_treatment_window,\n",
    "                                   metric_func, index_name):\n",
    "            x_pre_train = x[0:pre_treatment_window[0]]\n",
    "            y_pre_train = y[0:pre_treatment_window[0]]\n",
    "            x_pre_test = x[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "            y_pre_test = y[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "            x_pst_test = x[-1*(pre_treatment_window[0]+pre_treatment_window[1]):].copy()\n",
    "            y_pst_test = y[-1*(pre_treatment_window[0]+pre_treatment_window[1]):].copy()\n",
    "            test_pre_train = metric_func(x_pre_train, y_pre_train)\n",
    "            test_pre_test  = metric_func(x_pre_test,  y_pre_test)\n",
    "            test_pst_test  = metric_func(x_pst_test,  y_pst_test)\n",
    "            \n",
    "            return pd.DataFrame(index=[index_name], data={'test_pre_train':test_pre_train,\n",
    "                   'test_pre_test':test_pre_test,\n",
    "                   'test_pst_test':test_pst_test})\n",
    "\n",
    "        ## Compare the predicted treatment with the observed treatment\n",
    "        treat_hat_treat_obs = comparison_over_windows(y_treat_hat, y_treat_obs,\n",
    "                                                   pre_treatment_window,\n",
    "                                                   mean_absolute_percentage_error,'mape_vs_treat_obs')\n",
    "        return treat_hat_treat_obs\n",
    "\n",
    "    def sc_validation_gather(counterfactual=None,\n",
    "                              actual=None,\n",
    "                             pre_treatment_window=None):\n",
    "        from sklearn.metrics import mean_absolute_percentage_error        \n",
    "\n",
    "        x_pre_train = counterfactual[0:pre_treatment_window[0]]\n",
    "        y_pre_train = actual[0:pre_treatment_window[0]]\n",
    "        x_pre_test = counterfactual[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "        y_pre_test = actual[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "        x_pst_test = counterfactual[-1*(pre_treatment_window[0]+pre_treatment_window[1]):].copy()\n",
    "        y_pst_test = actual[-1*(pre_treatment_window[0]+pre_treatment_window[1]):].copy()\n",
    "        test_pre_train = mean_absolute_percentage_error(x_pre_train, y_pre_train)\n",
    "        test_pre_test  = mean_absolute_percentage_error(x_pre_test,  y_pre_test)\n",
    "        test_pst_test  = mean_absolute_percentage_error(x_pst_test,  y_pst_test)\n",
    "            \n",
    "        return pd.DataFrame(index=['mape_test'], data={'test_pre_train':test_pre_train,\n",
    "               'test_pre_test':test_pre_test,\n",
    "               'test_pst_test':test_pst_test})\n",
    "\n",
    "    '''\n",
    "    Output a dataframe collecting different metrics for each treated unit,\n",
    "    such as the ATET, p-value, confidence interval, and placebo tests.\n",
    "    \n",
    "    All confidence intervals and p-values to be calculated for individual post-treatment periods\n",
    "    '''\n",
    "    def collect_sc_outputs(sc_output = None,\n",
    "                           pre_process_data=None,\n",
    "                           theta_grid = None,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=None,\n",
    "                           aggregate_pst_periods=True,\n",
    "                      alpha = 0.05):\n",
    "        if aggregate_pst_periods==True:\n",
    "            a = sc.collect_sc_outputs_aggregate(sc_output = sc_output,\n",
    "                           pre_process_data=pre_process_data,\n",
    "                           theta_grid = theta_grid,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=pre_treatment_window,\n",
    "                      alpha = 0.05)\n",
    "        else:\n",
    "            a = sc.collect_sc_outputs_individual(sc_output = sc_output,\n",
    "               pre_process_data=pre_process_data,\n",
    "               theta_grid = theta_grid,  # np.arange(-10,10,0.5),\n",
    "               pre_treatment_window=pre_treatment_window,\n",
    "              alpha = 0.05)\n",
    "        return a\n",
    "    def collect_sc_outputs_individual(sc_output = None,\n",
    "                           pre_process_data=None,\n",
    "                           theta_grid = None,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=None,\n",
    "                           aggregate_pst_periods=True,\n",
    "                      alpha = 0.05):\n",
    "        ## To do the individual results, just call the function that does that aggregated\n",
    "        ## results multiple times, assuming that there is only one post-treatment period.\n",
    "        \n",
    "        ## Calculate some primatives:\n",
    "        pre_T = pre_process_data['T_pre'].shape[0]\n",
    "        pst_T = pre_process_data['T_pst'].shape[0]\n",
    "        permutations_subset_block_individual = []\n",
    "        for i in range(pre_T+1):\n",
    "            half_A = time_list[-1*(pre_T-i):].copy()\n",
    "            half_B = time_list[0:i]\n",
    "            scrambled_list = np.concatenate([half_A, half_B]) \n",
    "            permutations_subset_block_individual.append( list(scrambled_list)  )\n",
    "        \n",
    "        collect_individual_df = pd.DataFrame()\n",
    "        for t_pst in range(1, pst_T+1):\n",
    "            pst_index = np.append(np.arange(pre_periods) ,[pre_T+t_pst]) \n",
    "            sc_output_subset = {'atet':sc_output['atet'].iloc[pst_index],\n",
    "                               'predict_est':sc_output['predict_est'].iloc[pst_index],}\n",
    "            pre_process_data_subset = {'time_scramble': permutations_subset_block_individual,\n",
    "                                      'treatment_window':pre_process_data['treatment_window'].copy()}\n",
    "            a = collect_sc_outputs_aggregate(sc_output = sc_output_subset,\n",
    "                                       pre_process_data=pre_process_data_subset,\n",
    "                                       theta_grid = theta_grid,\n",
    "                                       pre_treatment_window=pre_process_data['treatment_window'],\n",
    "                                  alpha = 0.05)\n",
    "            a['individual_post']     = t_pst\n",
    "            collect_individual_df = pd.concat([collect_individual_df, a])\n",
    "        return collect_individual_df\n",
    "    \n",
    "    def collect_sc_outputs_aggregate(sc_output = None,\n",
    "                           pre_process_data=None,\n",
    "                           theta_grid = None,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=None,\n",
    "                      alpha = 0.05): \n",
    "        sc_results = sc_output['atet'].mean(axis=0).copy().to_frame().rename(columns={0:'atet'})\n",
    "            \n",
    "        sc_pv = []\n",
    "        sc_ci_05 = []\n",
    "        sc_ci_95 = []\n",
    "        sc_se = []\n",
    "        sc_placebo_pre_train = []\n",
    "        sc_placebo_pre_test = []\n",
    "        sc_placebo_pst_test = []\n",
    "            \n",
    "        o = 0\n",
    "        for p in [x for x in sc_output['predict_est'].columns if '_est' not in x]:\n",
    "            ## Calculate the p-value\n",
    "            pv_output = conformal_inf.pvalue_calc(counterfactual=np.array( sc_output['predict_est']['{0}_est'.format(p)].tolist() ),\n",
    "                                      actual=np.array( sc_output['predict_est']['{0}'.format(p)].tolist() ),\n",
    "                                      permutation_list =pre_process_data['time_scramble'],\n",
    "                                      treatment_window = pre_process_data['treatment_window'],\n",
    "                                      h0=0)\n",
    "            sc_pv.append(pv_output)\n",
    "\n",
    "            ## Calculate the confidence interval\n",
    "            ## If no pre-defined theta grid is defined, then just look 100 values in either direction\n",
    "            ## of the ATET estimate\n",
    "            if theta_grid is None:\n",
    "                i = sc_results['atet'].iloc[o]/100\n",
    "                theta_grid_use = np.arange(-500*i+sc_results['atet'].iloc[o],\n",
    "                                      -500*i+sc_results['atet'].iloc[o], i*5 )            \n",
    "            else:\n",
    "                theta_grid_use = theta_grid.copy()\n",
    "            \n",
    "            ci_output = conformal_inf.ci_calc(y_hat=sc_output['predict_est']['{0}_est'.format(p)].values,\n",
    "                           y_act=sc_output['predict_est']['{0}'.format(p)].values,\n",
    "                           theta_grid=theta_grid_use,\n",
    "                           permutation_list_ci =pre_process_data['time_scramble'],\n",
    "                           treatment_window_ci = pre_process_data['treatment_window'],\n",
    "                           alpha=alpha)\n",
    "#             print( ci_output['theta_list'] )\n",
    "#             print( ci_output['pvalue_list'] )\n",
    "            sc_ci_05.append(ci_output['ci_interval'][0])\n",
    "            sc_ci_95.append(ci_output['ci_interval'][1])\n",
    "\n",
    "            ## Calculate the placebo tests for that treated unit too\n",
    "            placebo_df = sc.sc_validation_gather(counterfactual=np.array( sc_output['predict_est']['{0}_est'.format(p)].tolist() ),\n",
    "                                      actual=np.array( sc_output['predict_est']['{0}'.format(p)].tolist() ),\n",
    "                                     pre_treatment_window=pre_process_data['treatment_window'])\n",
    "            sc_placebo_pre_train.append(placebo_df['test_pre_train'].values[0])\n",
    "            sc_placebo_pre_test.append( placebo_df['test_pre_test'].values[0])\n",
    "            sc_placebo_pst_test.append( placebo_df['test_pst_test'].values[0]) \n",
    "            o+=1\n",
    "\n",
    "        sc_results['pvalues'] = sc_pv\n",
    "        sc_results['ci_lower'] = sc_ci_05\n",
    "        sc_results['ci_upper'] = sc_ci_95\n",
    "        sc_results['alpha'] = alpha\n",
    "        sc_results['test_pre_train_MAPE'] = sc_placebo_pre_train\n",
    "        sc_results['test_pre_test_MAPE'] = sc_placebo_pre_test\n",
    "        sc_results['test_pst_test_MAPE'] = sc_placebo_pst_test\n",
    "        \n",
    "        return sc_results\n",
    "\n",
    "    \n",
    "## DGP and functions to determine what types of SC models to do, and calculate primatives for SC models\n",
    "class dgp:    \n",
    "    def determine_pre_treatment_window(ci_data_output=None,\n",
    "                                      pre_treatment_window=None):\n",
    "        if pre_treatment_window ==None:\n",
    "            pre_treatment_len = ci_data_output['C_pre'].shape[0]\n",
    "            pre_t0 = int( 0.75*pre_treatment_len )\n",
    "            if pre_t0 < 1:\n",
    "                pre_t0=1\n",
    "            else:\n",
    "                pass            \n",
    "            pre_t1 = pre_treatment_len - pre_t0\n",
    "            pre_treatment_window = [pre_t0, pre_t1]\n",
    "        else:\n",
    "            pass\n",
    "        return pre_treatment_window \n",
    "    \n",
    "    def clean_and_input_data(dataset=None, \n",
    "                             treatment='treated_unit', \n",
    "                             unit_id = 'unitid',\n",
    "                             date='T',\n",
    "                             post='post', outcome='Y'):\n",
    "        \n",
    "        C_pre = dataset.loc[(dataset[treatment]==0) & (dataset[post]==0)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        C_pst = dataset.loc[(dataset[treatment]==0) & (dataset[post]==1)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pre = dataset.loc[(dataset[treatment]==1) & (dataset[post]==0)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pst = dataset.loc[(dataset[treatment]==1) & (dataset[post]==1)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        \n",
    "        permutations_subset_block = conformal_inf.time_block_permutation(data=dataset, \n",
    "                                                                         time_unit=date,\n",
    "                                                                         post=post)\n",
    "                \n",
    "        return {'C_pre':C_pre, 'C_pst':C_pst, 'T_pre':T_pre, 'T_pst':T_pst, \n",
    "                'time_scramble':permutations_subset_block[0],\n",
    "               'treatment_window':permutations_subset_block[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6a44a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doudchenko Imbens, (2016) Model\n",
    "class di:\n",
    "    def estimate_mu_omega(treatment_pre, control_pre, alpha_lambda_0):\n",
    "        alpha_0, lambda_0 = alpha_lambda_0[0], alpha_lambda_0[1]\n",
    "        elnet = ElasticNet(random_state=2736, alpha=alpha_0, l1_ratio=lambda_0)\n",
    "        elnet.fit(control_pre, treatment_pre )\n",
    "        ## Output interpretable weights\n",
    "        try:\n",
    "            df_weights= pd.DataFrame(data=zip(treatment_pre.columns,\n",
    "                                              elnet.coef_.T\n",
    "                                             ))\n",
    "        except:\n",
    "            df_weights = pd.DataFrame(index=np.arange(len(elnet.coef_)), \n",
    "                         data=elnet.coef_.T)        \n",
    "        return {'mu': elnet.intercept_, 'omega': elnet.coef_, 'weights':df_weights, 'full':elnet}\n",
    "\n",
    "    def predict_mu_omega(treatment_pre, control_pre, alpha_lambda_0, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]].copy()\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]] .copy()   \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:].copy()\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:].copy()\n",
    "        \n",
    "        ## Estimate the DI model\n",
    "        holdout_dict = di.estimate_mu_omega(treatment_holdout, control_holdout, alpha_lambda_0)\n",
    "        if treatment_pre.shape[1]==1:\n",
    "            holdout_dict['omega'] = np.array([holdout_dict['omega']])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "        diff_holdout = treatment_holdout       -\\\n",
    "            np.dot(control_holdout, holdout_dict['omega'].T)+holdout_dict['mu']        \n",
    "        diff_nonholdout = treatment_nonholdout -\\\n",
    "            np.dot(control_nonholdout, holdout_dict['omega'].T)+holdout_dict['mu']\n",
    "\n",
    "        diff_nonholdout_mse = (diff_nonholdout**2).mean()\n",
    "        diff_holdout_mse = (diff_holdout**2).mean()\n",
    "        return {'mu':     holdout_dict['mu'],\n",
    "               'omega':   holdout_dict['omega'],\n",
    "               'weights': holdout_dict['weights'],\n",
    "               'full':    holdout_dict['full'],\n",
    "               'mse_holdout': diff_holdout_mse,\n",
    "               'mse_nonholdout':diff_nonholdout_mse}\n",
    "    \n",
    "    def sc_style_results(treatment_pre, treatment_pst, control_pre, control_pst, mu,omega):\n",
    "        ## Do some normalization of the omega input\n",
    "        if len(omega.shape) > 2:\n",
    "            omega = omega.reshape(omega.shape[-2],omega.shape[-1])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        final_X = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        control_X = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        control_df = mu + pd.DataFrame(data=np.dot(control_X, omega.T), columns=[ l+'_est' for l in final_X.columns ])\n",
    "        control_df.index = final_X.index\n",
    "        \n",
    "        output_df = control_df.join(final_X)\n",
    "        \n",
    "        treatment_periods = -1*len(treatment_pst)\n",
    "        atet_df = pd.DataFrame()\n",
    "        for c in [l for l in output_df.columns if '_est' not in l]:\n",
    "            diff = output_df[c][treatment_periods:].copy() - output_df[c+'_est'][treatment_periods:].copy()\n",
    "            atet_df[c] = diff\n",
    "        \n",
    "        return {'atet': atet_df , 'predict_est':output_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "5ca4ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here code up the functions that we will try to minimize over\n",
    "class alpha_lambda:\n",
    "    def diff(y_t,y_c, mu_x, omega_x):\n",
    "        return y_t - mu_x - np.dot(y_c,omega_x)\n",
    "\n",
    "    def alpha_lambda_transform(alpha_lambda_raw_):\n",
    "        ## Alpha is strictly greater than zero\n",
    "        ## lambda exists between 0 and 1\n",
    "        return np.exp(alpha_lambda_raw_[0]/1000), np.exp(alpha_lambda_raw_[1])/(1+np.exp(alpha_lambda_raw_[1])), \n",
    "    def alpha_lambda_diff(alpha_lambda_raw_, control_pre):\n",
    "        ## Transform the inputted alpha,lambda values \n",
    "        alpha_lambda_t = alpha_lambda.alpha_lambda_transform(alpha_lambda_raw_)\n",
    "        difference_array = []\n",
    "        ## Pick one control unit as the pretend treatment unit\n",
    "        for u in control_pre.columns:\n",
    "            control_pre_placebo_treat = control_pre[u]\n",
    "            control_pre_placebo_cntrl = control_pre[ [l for l in control_pre.columns if l !=u] ]\n",
    "\n",
    "            ## Estimate mu and lambda with that control unit\n",
    "            control_pre_placebo_w = di.estimate_mu_omega(control_pre_placebo_treat,\n",
    "                             control_pre_placebo_cntrl,\n",
    "                             alpha_lambda_t)\n",
    "            ## Estimate the difference\n",
    "            d = alpha_lambda.diff(control_pre_placebo_treat, \n",
    "                 control_pre_placebo_cntrl, \n",
    "                 control_pre_placebo_w['mu'],\n",
    "                 control_pre_placebo_w['omega'])\n",
    "            difference_array.append(d)\n",
    "        ## Estimate the difference across all the control units\n",
    "        d_mean = np.mean(difference_array)\n",
    "        return d_mean\n",
    "    def get_alpha_lambda(control_pre_input):\n",
    "        ## Initialize at a given point\n",
    "        weights = minimize(partial(alpha_lambda.alpha_lambda_diff, control_pre=control_pre_input),\n",
    "                             np.array([10.15,0.5]),\n",
    "                           method='BFGS',\n",
    "                          options={'maxiter':5000, 'gtol': 1e-07, 'disp':False})\n",
    "        return weights\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "488a1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constrained Lasso Model\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class cl:\n",
    "    def cl_obj(params, y,x) -> float:\n",
    "        return np.mean(  (y - params[0] - np.dot(x,params[1:]))**2)\n",
    "    \n",
    "    def predict_mu_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]].copy()\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]].copy()    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:].copy()\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:].copy()\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['mu'] = []\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        if treatment_pre.shape[1] > 1:\n",
    "            for t in treatment_pre.columns:\n",
    "                t_dict = cl.get_mu_omega(treatment_holdout[t], control_holdout)\n",
    "                ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "                diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict['omega'].T)+t_dict['mu']\n",
    "                diff_h_mse = (diff_h**2).mean()\n",
    "                diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict['omega'].T)+t_dict['mu']\n",
    "                diff_nh_mse = (diff_nh**2).mean()\n",
    "        \n",
    "                holdout_dict['mu'].append(t_dict['mu'])\n",
    "                holdout_dict['omega'].append(t_dict['omega'])\n",
    "                holdout_dict['weights'].append(t_dict['weights'])\n",
    "                diff_holdout_mse.append(diff_h_mse)\n",
    "                diff_nonholdout_mse.append(diff_nh_mse)\n",
    "        else:\n",
    "            \n",
    "            t_dict = cl.get_mu_omega(treatment_holdout.values.flatten(), control_holdout)\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            t_dict['omega'] = np.array([t_dict['omega']])\n",
    "            diff_h= treatment_holdout       - np.dot(control_holdout, t_dict['omega'].T)+t_dict['mu']\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout - np.dot(control_nonholdout, t_dict['omega'].T)+t_dict['mu']\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['mu'].append(t_dict['mu'])\n",
    "            holdout_dict['omega'].append(t_dict['omega'])\n",
    "            holdout_dict['weights'].append(t_dict['weights'])\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)            \n",
    "                    \n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        if len(holdout_dict['omega'].shape) > 2:\n",
    "            holdout_dict['omega'] = holdout_dict['omega'].reshape(holdout_dict['omega'].shape[-2],holdout_dict['omega'].shape[-1])\n",
    "        else:\n",
    "            pass        \n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "\n",
    "        return holdout_dict\n",
    "\n",
    "\n",
    "    def get_mu_omega(treatment_pre_input, control_pre_input):\n",
    "        n = control_pre_input.shape[1]\n",
    "        initialx = np.ones(n+1)/1\n",
    "        ## Initialize at a given point\n",
    "        weights = fmin_slsqp(partial(cl.cl_obj, y=treatment_pre_input,\n",
    "                                  x=control_pre_input),\n",
    "                             initialx,\n",
    "                             f_ieqcons=lambda x: 1-np.sum(np.abs(x[1:])),\n",
    "                         iter=50000, \n",
    "                         disp=False)\n",
    "        mu, omega = weights[0], weights[1:]\n",
    "        return {'mu':mu, 'omega':omega, 'weights':weights}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "2d4eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abadie, Diamond, Hainmueller (2010) model\n",
    "## Also code up the ADH weights\n",
    "## Abadie/Diamond/Hainmueller    \n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class adh:\n",
    "    ## Define loss function\n",
    "    def loss_w(W, X, y) -> float:\n",
    "        return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "    def get_w(X, y):\n",
    "        ## Initialize at sample average with some noise\n",
    "        w_start = [1/X.shape[1]]*X.shape[1]\n",
    "    #     w_start = np.ones(X.shape[1])\n",
    "\n",
    "        weights = fmin_slsqp(partial(adh.loss_w, X=X, y=y),\n",
    "                             np.array(w_start),\n",
    "                             f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                             iter=50000, \n",
    "                             bounds=[(0.0, 1.0)]*len(w_start),\n",
    "                             disp=False)\n",
    "        return weights   \n",
    "    \n",
    "    def predict_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]].copy()\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]].copy()    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:].copy()\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:].copy()\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        if treatment_pre.shape[1] > 1:\n",
    "            for t in treatment_pre.columns:\n",
    "                t_dict = adh.get_w(control_holdout,treatment_holdout[t])\n",
    "                ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "                diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict.T)\n",
    "                diff_h_mse = (diff_h**2).mean()\n",
    "                diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict.T)\n",
    "                diff_nh_mse = (diff_nh**2).mean()\n",
    "        \n",
    "                holdout_dict['omega'].append(t_dict)\n",
    "                holdout_dict['weights'].append(t_dict)\n",
    "                diff_holdout_mse.append(diff_h_mse)\n",
    "                diff_nonholdout_mse.append(diff_nh_mse)\n",
    "        else:\n",
    "            t_dict = adh.get_w(control_holdout,treatment_holdout.values.flatten())\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            diff_h= treatment_holdout       - np.dot(control_holdout, np.array([t_dict]).T)\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout - np.dot(control_nonholdout, np.array([t_dict]).T)\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['omega'].append(t_dict)\n",
    "            holdout_dict['weights'].append(t_dict)\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)            \n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "        \n",
    "        return holdout_dict    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5f16606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conformal Inference to do inference for the SC models\n",
    "import itertools\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "rng.choice(10, size=10, replace=False)\n",
    "\n",
    "\n",
    "class conformal_inf:\n",
    "    def time_block_permutation(data=None,\n",
    "                              time_unit='date',\n",
    "                              post='W'):\n",
    "        tw =  len(data.loc[ data[post]==1][time_unit].unique())\n",
    "        treatment_window = len(data.loc[(data[post]==0)][time_unit].unique())-tw, tw\n",
    "\n",
    "        time_list = np.arange( np.sum(treatment_window) )\n",
    "        T_len = len(time_list)\n",
    "\n",
    "        ## Time block permutations\n",
    "        permutations_subset_block = []\n",
    "\n",
    "        for i in range(T_len):\n",
    "            half_A = time_list[-1*(T_len-i):]\n",
    "            half_B = time_list[0:i]\n",
    "            scrambled_list = np.concatenate([half_A, half_B]) \n",
    "            permutations_subset_block.append( list(scrambled_list)  )\n",
    "\n",
    "        return permutations_subset_block, treatment_window\n",
    "\n",
    "\n",
    "    def scrambled_residual(counterfactual, actual, \n",
    "                       scrambled_order,\n",
    "                      treatment_window):\n",
    "        '''\n",
    "        counterfactual   array of counterfactual estimates that are assumed to be ordered sequentially\n",
    "        actual           ``'' for actual values\n",
    "        scrambled_order  integer array that tells me how to scramble these\n",
    "        treatment_window list of two integers for the number of pre-treatment and post-treatment units\n",
    "        '''\n",
    "        counterfactual_ = counterfactual[scrambled_order].copy()        \n",
    "        actual_         = actual[scrambled_order].copy()\n",
    "        return np.abs(actual_ - counterfactual_)[ -1*treatment_window[1]:]\n",
    "    \n",
    "    def test_statS(q, treatment_window, residual_abs):\n",
    "        normed = np.sum(  np.power(residual_abs, q) )\n",
    "        return np.power( treatment_window[1]**(-0.5)*normed , 1/q)    \n",
    "\n",
    "    def pvalue_calc(counterfactual=None,\n",
    "                    actual=None, \n",
    "                    permutation_list=None,\n",
    "                   treatment_window=None,\n",
    "                   h0 = 0):\n",
    "        control_pst = counterfactual[-1*treatment_window[1]:].copy()\n",
    "        actual_pst  = actual[-1*treatment_window[1]:].copy()\n",
    "        actual_pst -= h0\n",
    "\n",
    "        ## Calculate the residual\n",
    "        residual_initial = np.abs(actual_pst - control_pst)         \n",
    "        S_q = conformal_inf.test_statS(1, treatment_window, residual_initial)\n",
    "        ## Now do a whole bunch of treatment time scrambles\n",
    "        ## We're going to permute over all time-based permutations\n",
    "        ## Adjust the actual by the null hypothesis \n",
    "        treat_ = actual.copy()\n",
    "        treat_[-1*treatment_window[1]:] -= h0\n",
    "        full_residual = np.abs(treat_ - counterfactual)\n",
    "        S_q_pi = []\n",
    "        for r in permutation_list:\n",
    "            scrambled_dates = np.array(list(r))              \n",
    "            residual_ = full_residual[scrambled_dates][-1*treatment_window[1]:].copy()\n",
    "            S_q_pi.append(  conformal_inf.test_statS(1, treatment_window, residual_ )  )\n",
    "            \n",
    "        p_value = 1 - np.average( (np.array(S_q_pi) < S_q ) )\n",
    "        return p_value\n",
    "    \n",
    "    def ci_calc(y_hat=None,\n",
    "               y_act=None,\n",
    "               theta_grid=None,\n",
    "                permutation_list_ci = None,\n",
    "                treatment_window_ci =None,\n",
    "               alpha=0.05):\n",
    "        pv_grid = []\n",
    "        for t in theta_grid:\n",
    "            pv = conformal_inf.pvalue_calc(counterfactual=y_hat.copy(),\n",
    "                        actual=y_act.copy(), \n",
    "                            permutation_list = permutation_list_ci,\n",
    "                           treatment_window = treatment_window_ci,\n",
    "                                 h0=t)\n",
    "            pv_grid.append(pv)   \n",
    "        ci_list = [ theta_grid[i] for i in range(len(pv_grid)) if pv_grid[i] > alpha ]\n",
    "        return {'theta_list':theta_grid, 'pvalue_list':pv_grid, 'ci_list':ci_list,\n",
    "               'ci_interval':[np.min(ci_list), np.max(ci_list)]}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83611126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b3391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3670939a",
   "metadata": {},
   "source": [
    "Test these functions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a615d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "N = 50\n",
    "initial = np.random.uniform(0,1, N)\n",
    "df = pd.DataFrame(data={'y':initial,\n",
    "                  'unit_id':np.arange(N),\n",
    "                       'time':np.zeros(N).astype(int)})\n",
    "for t in range(40):\n",
    "    entry = df.iloc[-1*N:]\n",
    "    entry['y'] = entry['y']*0.80 + np.random.normal(0,5,N)*0.20\n",
    "    entry.loc[[True]*N,'time'] = t\n",
    "    df = pd.concat([df,entry])\n",
    "df['treated']        = df['unit_id'].isin([0,1,2])\n",
    "df['post'] = (df['time'] > 30)\n",
    "df['W'] =     df['treated']*    df['post']\n",
    "df['unit_id'] = df['unit_id'].apply(str)\n",
    "df.loc[df['W']==True, 'y'] += 0.50\n",
    "## Clean data\n",
    "\n",
    "sc_dict = dgp.clean_and_input_data(dataset=df,\n",
    "                                   treatment='treated',\n",
    "                                   unit_id='unit_id',\n",
    "                                   date='time',\n",
    "                                   post='post',\n",
    "                                  outcome='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fddc48fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240308</td>\n",
       "      <td>0.517416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.451261</td>\n",
       "      <td>0.353696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.471953</td>\n",
       "      <td>0.298897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.233254</td>\n",
       "      <td>0.195945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321405</td>\n",
       "      <td>0.120244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143145</td>\n",
       "      <td>-0.022931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.248501</td>\n",
       "      <td>-0.008173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.468888</td>\n",
       "      <td>-0.199010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.147165</td>\n",
       "      <td>-0.140927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.907690</td>\n",
       "      <td>-0.055904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3.911274</td>\n",
       "      <td>0.398912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.931074</td>\n",
       "      <td>0.491622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.177475</td>\n",
       "      <td>0.392926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.021408</td>\n",
       "      <td>0.432251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.203962</td>\n",
       "      <td>0.243193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.904082</td>\n",
       "      <td>0.360115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.470567</td>\n",
       "      <td>0.303284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.943304</td>\n",
       "      <td>0.507726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.587692</td>\n",
       "      <td>0.475653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.113271</td>\n",
       "      <td>0.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.453831</td>\n",
       "      <td>0.044577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.454868</td>\n",
       "      <td>-0.130019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.317741</td>\n",
       "      <td>-0.128429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.334893</td>\n",
       "      <td>-0.183302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.481810</td>\n",
       "      <td>-0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.910629</td>\n",
       "      <td>-0.296174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.564132</td>\n",
       "      <td>-0.065714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.056747</td>\n",
       "      <td>-0.140246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.026996</td>\n",
       "      <td>0.158327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.478505</td>\n",
       "      <td>0.242631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.246395</td>\n",
       "      <td>0.521460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.584595</td>\n",
       "      <td>0.325183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.431370</td>\n",
       "      <td>0.266877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.295514</td>\n",
       "      <td>0.184264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.995987</td>\n",
       "      <td>0.117934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.176435</td>\n",
       "      <td>0.086976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.759097</td>\n",
       "      <td>-0.099816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.540021</td>\n",
       "      <td>-0.231049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.375506</td>\n",
       "      <td>-0.219158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.925188</td>\n",
       "      <td>0.006698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y         y\n",
       "time                    \n",
       "0     0.240308  0.517416\n",
       "1    -0.451261  0.353696\n",
       "2    -0.471953  0.298897\n",
       "3    -0.233254  0.195945\n",
       "4     0.321405  0.120244\n",
       "5     0.143145 -0.022931\n",
       "6     0.248501 -0.008173\n",
       "7    -0.468888 -0.199010\n",
       "8    -1.147165 -0.140927\n",
       "9    -2.907690 -0.055904\n",
       "10   -3.911274  0.398912\n",
       "11   -2.931074  0.491622\n",
       "12   -2.177475  0.392926\n",
       "13   -1.021408  0.432251\n",
       "14   -1.203962  0.243193\n",
       "15   -0.904082  0.360115\n",
       "16   -0.470567  0.303284\n",
       "17    0.943304  0.507726\n",
       "18    0.587692  0.475653\n",
       "19    1.113271  0.178917\n",
       "20    1.453831  0.044577\n",
       "21    1.454868 -0.130019\n",
       "22    1.317741 -0.128429\n",
       "23    1.334893 -0.183302\n",
       "24    0.481810 -0.232985\n",
       "25    0.910629 -0.296174\n",
       "26    1.564132 -0.065714\n",
       "27    2.056747 -0.140246\n",
       "28    2.026996  0.158327\n",
       "29    1.478505  0.242631\n",
       "30    1.246395  0.521460\n",
       "31    1.584595  0.325183\n",
       "32    1.431370  0.266877\n",
       "33    1.295514  0.184264\n",
       "34    0.995987  0.117934\n",
       "35    1.176435  0.086976\n",
       "36    1.759097 -0.099816\n",
       "37    1.540021 -0.231049\n",
       "38    1.375506 -0.219158\n",
       "39    0.925188  0.006698"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    df.loc[df['treated']==1].groupby('time')['y'].mean(), \n",
    "    df.loc[df['treated']==0].groupby('time')['y'].mean()] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "70b27ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_window_pre_treatment = dgp.determine_pre_treatment_window(ci_data_output=sc_dict, pre_treatment_window=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "cc705b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Figure out the alpha and lambda values\n",
    "# w=alpha_lambda.get_alpha_lambda(sc_dict['C_pre'])\n",
    "# alpha_lambda_to_use = alpha_lambda.alpha_lambda_transform(w.x)\n",
    "# ## Take the alpha and lambda values, and estimate mu and omega\n",
    "# di_est = di.predict_mu_omega(sc_dict['T_pre'], sc_dict['C_pre'], alpha_lambda_to_use, \n",
    "#                              treatment_window_pre_treatment)\n",
    "# di_output = di.sc_style_results(sc_dict['T_pre'], sc_dict['T_pst'],\n",
    "#                     sc_dict['C_pre'], sc_dict['C_pst'],\n",
    "#                         di_est['mu'],di_est['omega'])\n",
    "# di_validation = sc.sc_validation(treatment_pre=sc_dict['T_pre'], \n",
    "#                  treatment_pst=sc_dict['T_pst'],\n",
    "#                  control_pre=sc_dict['C_pre'],\n",
    "#                  control_pst=sc_dict['C_pst'], \n",
    "#                  mu=di_est['mu'],\n",
    "#                  omega=di_est['omega'],\n",
    "#                  pre_treatment_window=treatment_window_pre_treatment)\n",
    "# cl_output['predict_est']\n",
    "\n",
    "ak7 = cl.predict_mu_omega(sc_dict['T_pre'], sc_dict['C_pre'], treatment_window_pre_treatment)\n",
    "cl_output = di.sc_style_results(sc_dict['T_pre'], sc_dict['T_pst'],\n",
    "                    sc_dict['C_pre'], sc_dict['C_pst'],\n",
    "                    ak7['mu'], ak7['omega'])\n",
    "sc_validation = sc.sc_validation(treatment_pre=sc_dict['T_pre'], \n",
    "                 treatment_pst=sc_dict['T_pst'],\n",
    "                 control_pre=sc_dict['C_pre'],\n",
    "                 control_pst=sc_dict['C_pst'], \n",
    "                 mu=ak7['mu'],\n",
    "                 omega=ak7['omega'],\n",
    "                 pre_treatment_window=treatment_window_pre_treatment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "41265507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25806451612903225\n"
     ]
    }
   ],
   "source": [
    "## Improve on this by calling for inference results\n",
    "# sc_df_results = sc.collect_sc_outputs(sc_output = di_output,\n",
    "#                    pre_process_data=sc_dict,\n",
    "#                theta_grid = np.arange(-10,10,0.5),\n",
    "#                    pre_treatment_window=treatment_window_pre_treatment, \n",
    "#                                       alpha = 0.05)\n",
    "\n",
    "c_y = np.array( cl_output['predict_est']['1_est'].tolist() )\n",
    "c_x = np.array( cl_output['predict_est']['1'].tolist() ) \n",
    "a = conformal_inf.pvalue_calc(counterfactual=c_y,\n",
    "                          actual=c_x,\n",
    "                          permutation_list =sc_dict['time_scramble'],\n",
    "                          treatment_window = sc_dict['treatment_window'],\n",
    "                          h0=0)\n",
    "print(a)\n",
    "a_pert_lit = []\n",
    "theta_list = np.arange(-2,2,0.10)\n",
    "for r in theta_list:\n",
    "    b = conformal_inf.pvalue_calc(counterfactual=c_y  ,\n",
    "                actual=c_x , \n",
    "                    permutation_list = sc_dict['time_scramble'],\n",
    "                   treatment_window = sc_dict['treatment_window'],\n",
    "                         h0=r)\n",
    "    a_pert_lit.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4c8e750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data={'pv':a_pert_lit, 'theta':theta_list } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1f7103fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atet</th>\n",
       "      <th>pvalues</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>alpha</th>\n",
       "      <th>test_pre_train_MAPE</th>\n",
       "      <th>test_pre_test_MAPE</th>\n",
       "      <th>test_pst_test_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.126707</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.680810</td>\n",
       "      <td>11.943708</td>\n",
       "      <td>4.882176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884820</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.207898</td>\n",
       "      <td>1.160217</td>\n",
       "      <td>3.459132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.662562</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.856067</td>\n",
       "      <td>3.393377</td>\n",
       "      <td>8.987389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       atet   pvalues  ci_lower  ci_upper  alpha  test_pre_train_MAPE  \\\n",
       "0  1.126707  0.258065      -0.5       3.0   0.05             0.680810   \n",
       "1  0.884820  0.258065       0.0       2.0   0.05             1.207898   \n",
       "2  1.662562  0.096774       0.0       3.0   0.05             1.856067   \n",
       "\n",
       "   test_pre_test_MAPE  test_pst_test_MAPE  \n",
       "0           11.943708            4.882176  \n",
       "1            1.160217            3.459132  \n",
       "2            3.393377            8.987389  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f3 = sc.sc_model(model_name='cl',\n",
    "        data=df,\n",
    "        data_dict={'treatment': 'treated',\n",
    "                  'date':'time',\n",
    "                  'post':'post',\n",
    "                  'unitid':'unit_id',\n",
    "                  'outcome':'y'},\n",
    "        pre_process_data=None,\n",
    "        pre_treatment_window=None)\n",
    "\n",
    "\n",
    "display( f3['results_df'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7844a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
