{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243a43a9",
   "metadata": {},
   "source": [
    "# panelby\n",
    "Julian Hsu\n",
    "This is our package for panel models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "348a8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from IPython.display import display    \n",
    "\n",
    "import scipy.stats \n",
    "from sklearn.linear_model import ElasticNet\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3f304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19989c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1fa4340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the univeral function that calls all the different SC models coded up below.\n",
    "## It will also call functions used for SC model validation\n",
    "\n",
    "class sc:\n",
    "    def sc_model(model_name='adh',\n",
    "                data=None,\n",
    "                data_dict= {'treatment':None, 'date':None, 'post':None, 'unitid':None, 'outcome':None},\n",
    "                pre_process_data=None,\n",
    "                pre_treatment_window=None):\n",
    "        ## First pre-process the data if possible.\n",
    "        if pre_process_data==None:\n",
    "            pre_process_data = dgp.clean_and_input_data(dataset=data,\n",
    "                                                        treatment=data_dict['treatment'],\n",
    "                                                        unit_id=data_dict['unitid'],\n",
    "                                                        date=data_dict['date'],\n",
    "                                                        post=data_dict['post'],\n",
    "                                                        outcome=data_dict['outcome'])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ## Second calculate the pre-treatment-window that can be useful for placebo tests\n",
    "        pre_treatment_window = dgp.determine_pre_treatment_window(ci_data_output=pre_process_data,\n",
    "                                                                 pre_treatment_window=pre_treatment_window)\n",
    "        \n",
    "        \n",
    "        ## Finally, call an SC model.\n",
    "        if model_name=='adh':\n",
    "            print('Using ADH')\n",
    "            sc_est = adh.predict_omega(pre_process_data['T_pre'], \n",
    "                                    pre_process_data['C_pre'], \n",
    "                                    pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'], \n",
    "                                             pre_process_data['T_pst'],\n",
    "                                             pre_process_data['C_pre'], \n",
    "                                             pre_process_data['C_pst'],\n",
    "                                np.zeros(pre_process_data['T_pst'].shape[1]), np.array(sc_est['omega']))\n",
    "            sc_est['mu'] = np.zeros( pre_process_data['T_pre'].shape[1] )\n",
    "            \n",
    "        elif model_name=='di':\n",
    "            print('Using DI')\n",
    "            w=alpha_lambda.get_alpha_lambda(sc_dict['C_pre'])\n",
    "            alpha_lambda_to_use = alpha_lambda.alpha_lambda_transform(w.x)\n",
    "            ## Take the alpha and lambda values, and estimate mu and omega\n",
    "            sc_est = di.predict_mu_omega(pre_process_data['T_pre'], \n",
    "                                         pre_process_data['C_pre'], alpha_lambda_to_use, \n",
    "                                         pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'], \n",
    "                                            pre_process_data['T_pst'],\n",
    "                                            pre_process_data['C_pre'], \n",
    "                                            pre_process_data['C_pst'],\n",
    "                                            sc_est['mu'],sc_est['omega'])\n",
    "            \n",
    "        elif model_name=='cl':\n",
    "            print('Using CL')\n",
    "            sc_est = cl.predict_mu_omega(pre_process_data['T_pre'],\n",
    "                                      pre_process_data['C_pre'], \n",
    "                                      pre_treatment_window)\n",
    "            sc_output = di.sc_style_results(pre_process_data['T_pre'],\n",
    "                                            pre_process_data['T_pst'],\n",
    "                                            pre_process_data['C_pre'], \n",
    "                                            pre_process_data['C_pst'],\n",
    "                                            sc_est['mu'], sc_est['omega']) \n",
    "        else:\n",
    "            print('SC Model name not supported. \\n [adh,di,cl] are supported models.')\n",
    "        \n",
    "        ## Output measures of fit pre-treatment (training), pre_treatment (test), and post-treatment\n",
    "        sc_validation = sc.sc_validation(treatment_pre=pre_process_data['T_pre'], \n",
    "                     treatment_pst=pre_process_data['T_pst'],\n",
    "                     control_pre=  pre_process_data['C_pre'],\n",
    "                     control_pst=  pre_process_data['C_pst'], \n",
    "                     mu=  sc_est['mu'],\n",
    "                     omega=sc_est['omega'],\n",
    "                     pre_treatment_window=pre_treatment_window)\n",
    "        \n",
    "        ## Improve on this by calling for inference results\n",
    "        sc_df_results = sc.collect_sc_outputs(sc_output = sc_output,\n",
    "                           pre_process_data=pre_process_data,\n",
    "                       theta_grid = np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=pre_treatment_window, alpha = 0.05)\n",
    "        \n",
    "        return {**sc_output, 'results_df':sc_df_results}\n",
    "\n",
    "\n",
    "    '''\n",
    "    Create a function that evaluates how well the SC model does at matching the:\n",
    "    1. pre-treatment data used for training;\n",
    "    2. pre-treatment data used for testing; and\n",
    "    3. the post-treatment data.\n",
    "    \n",
    "    Calculate metrics of fit and compare pre-treatment and post-treatment metrics.\n",
    "    '''\n",
    "    def sc_validation(treatment_pre, treatment_pst, control_pre, control_pst, \n",
    "                                      mu,omega,\n",
    "                                     pre_treatment_window):\n",
    "        ## Re-combine the observed treatment and control outcomes\n",
    "        y_treat_obs = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        y_control_obs = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        ## Estimate the counterfactual outcome of the treatment group\n",
    "        y_treat_hat = mu + np.dot(y_control_obs, omega.T)\n",
    "\n",
    "        from sklearn.metrics import mean_absolute_percentage_error\n",
    "        def comparison_over_windows(x,y,\n",
    "                                    pre_treatment_window,\n",
    "                                   metric_func, index_name):\n",
    "            x_pre_train = x[0:pre_treatment_window[0]]\n",
    "            y_pre_train = y[0:pre_treatment_window[0]]\n",
    "            x_pre_test = x[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "            y_pre_test = y[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "            x_pst_test = x[-1*(pre_treatment_window[0]+pre_treatment_window[1]):]\n",
    "            y_pst_test = y[-1*(pre_treatment_window[0]+pre_treatment_window[1]):]\n",
    "            test_pre_train = metric_func(x_pre_train, y_pre_train)\n",
    "            test_pre_test  = metric_func(x_pre_test,  y_pre_test)\n",
    "            test_pst_test  = metric_func(x_pst_test,  y_pst_test)\n",
    "            \n",
    "            return pd.DataFrame(index=[index_name], data={'test_pre_train':test_pre_train,\n",
    "                   'test_pre_test':test_pre_test,\n",
    "                   'test_pst_test':test_pst_test})\n",
    "\n",
    "        ## Compare the predicted treatment with the observed treatment\n",
    "        treat_hat_treat_obs = comparison_over_windows(y_treat_hat, y_treat_obs,\n",
    "                                                   pre_treatment_window,\n",
    "                                                   mean_absolute_percentage_error,'mape_vs_treat_obs')\n",
    "        return treat_hat_treat_obs\n",
    "\n",
    "    def sc_validation_gather(counterfactual=None,\n",
    "                              actual=None,\n",
    "                             pre_treatment_window=None):\n",
    "        from sklearn.metrics import mean_absolute_percentage_error        \n",
    "\n",
    "        x_pre_train = counterfactual[0:pre_treatment_window[0]]\n",
    "        y_pre_train = actual[0:pre_treatment_window[0]]\n",
    "        x_pre_test = counterfactual[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "        y_pre_test = actual[pre_treatment_window[0]:pre_treatment_window[0]+pre_treatment_window[1]]\n",
    "        x_pst_test = counterfactual[-1*(pre_treatment_window[0]+pre_treatment_window[1]):]\n",
    "        y_pst_test = actual[-1*(pre_treatment_window[0]+pre_treatment_window[1]):]\n",
    "        test_pre_train = mean_absolute_percentage_error(x_pre_train, y_pre_train)\n",
    "        test_pre_test  = mean_absolute_percentage_error(x_pre_test,  y_pre_test)\n",
    "        test_pst_test  = mean_absolute_percentage_error(x_pst_test,  y_pst_test)\n",
    "            \n",
    "        return pd.DataFrame(index=['mape_test'], data={'test_pre_train':test_pre_train,\n",
    "               'test_pre_test':test_pre_test,\n",
    "               'test_pst_test':test_pst_test})\n",
    "\n",
    "    '''\n",
    "    Output a dataframe collecting different metrics for each treated unit,\n",
    "    such as the ATET, p-value, confidence interval, and placebo tests.\n",
    "    \n",
    "    All confidence intervals and p-values to be calculated for individual post-treatment periods\n",
    "    '''\n",
    "    def collect_sc_outputs(sc_output = None,\n",
    "                           pre_process_data=None,\n",
    "                           theta_grid = None,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=None,\n",
    "                           aggregate_pst_periods=True,\n",
    "                      alpha = 0.05):\n",
    "        if aggregate_pst_periods==True:\n",
    "            a = sc.collect_sc_outputs_aggregate(sc_output = sc_output,\n",
    "                           pre_process_data=pre_process_data,\n",
    "                           theta_grid = theta_grid,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=pre_treatment_window,\n",
    "                      alpha = 0.05)\n",
    "        else:\n",
    "            a = sc.collect_sc_outputs_individual(sc_output = sc_output,\n",
    "               pre_process_data=pre_process_data,\n",
    "               theta_grid = theta_grid,  # np.arange(-10,10,0.5),\n",
    "               pre_treatment_window=pre_treatment_window,\n",
    "              alpha = 0.05)\n",
    "        return a\n",
    "    def collect_sc_outputs_individual(sc_output = None,\n",
    "                           pre_process_data=None,\n",
    "                           theta_grid = None,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=None,\n",
    "                           aggregate_pst_periods=True,\n",
    "                      alpha = 0.05):\n",
    "        ## To do the individual results, just call the function that does that aggregated\n",
    "        ## results multiple times, assuming that there is only one post-treatment period.\n",
    "        \n",
    "        ## Calculate some primatives:\n",
    "        pre_T = pre_process_data['T_pre'].shape[0]\n",
    "        pst_T = pre_process_data['T_pst'].shape[0]\n",
    "        permutations_subset_block_individual = []\n",
    "        for i in range(pre_T+1):\n",
    "            half_A = time_list[-1*(pre_T-i):]\n",
    "            half_B = time_list[0:i]\n",
    "            scrambled_list = np.concatenate([half_A, half_B]) \n",
    "            permutations_subset_block_individual.append( list(scrambled_list)  )\n",
    "        \n",
    "        collect_individual_df = pd.DataFrame()\n",
    "        for t_pst in range(1, pst_T+1):\n",
    "            pst_index = np.append(np.arange(pre_periods) ,[pre_T+t_pst]) \n",
    "            sc_output_subset = {'atet':sc_output['atet'].iloc[pst_index],\n",
    "                               'predict_est':sc_output['predict_est'].iloc[pst_index],}\n",
    "            pre_process_data_subset = {'time_scramble': permutations_subset_block_individual,\n",
    "                                      'treatment_window':pre_process_data['treatment_window'][:]}\n",
    "            a = collect_sc_outputs_aggregate(sc_output = sc_output_subset,\n",
    "                                       pre_process_data=pre_process_data_subset,\n",
    "                                       theta_grid = theta_grid,\n",
    "                                       pre_treatment_window=pre_process_data['treatment_window'],\n",
    "                                  alpha = 0.05)\n",
    "            a['individual_post']     = t_pst\n",
    "            collect_individual_df = pd.concat([collect_individual_df, a])\n",
    "        return collect_individual_df\n",
    "    \n",
    "    def collect_sc_outputs_aggregate(sc_output = None,\n",
    "                           pre_process_data=None,\n",
    "                           theta_grid = None,  # np.arange(-10,10,0.5),\n",
    "                           pre_treatment_window=None,\n",
    "                      alpha = 0.05): \n",
    "        sc_results = sc_output['atet'].mean(axis=0).copy().to_frame().rename(columns={0:'atet'})\n",
    "            \n",
    "        sc_pv = []\n",
    "        sc_ci_05 = []\n",
    "        sc_ci_95 = []\n",
    "        sc_se = []\n",
    "        sc_placebo_pre_train = []\n",
    "        sc_placebo_pre_test = []\n",
    "        sc_placebo_pst_test = []\n",
    "            \n",
    "        o = 0\n",
    "        for p in [x for x in sc_output['predict_est'].columns if '_est' not in x]:\n",
    "            ## Calculate the p-value\n",
    "            pv_output = conformal_inf.pvalue_calc(counterfactual=np.array( sc_output['predict_est']['{0}_est'.format(p)].tolist() ),\n",
    "                                      actual=np.array( sc_output['predict_est']['{0}'.format(p)].tolist() ),\n",
    "                                      permutation_list =pre_process_data['time_scramble'],\n",
    "                                      treatment_window = pre_process_data['treatment_window'],\n",
    "                                      h0=0)\n",
    "            sc_pv.append(pv_output)\n",
    "\n",
    "            ## Calculate the confidence interval\n",
    "            ## If no pre-defined theta grid is defined, then just look 100 values in either direction\n",
    "            ## of the ATET estimate\n",
    "            if theta_grid is None:\n",
    "                i = sc_results['atet'].iloc[o]/100\n",
    "                theta_grid_use = np.arange(-500*i+sc_results['atet'].iloc[o],\n",
    "                                      -500*i+sc_results['atet'].iloc[o], i*5 )            \n",
    "            else:\n",
    "                theta_grid_use = theta_grid[:]\n",
    "            ci_output = conformal_inf.ci_calc(y_hat=sc_output['predict_est']['{0}_est'.format(p)].values,\n",
    "                           y_act=sc_output['predict_est']['{0}'.format(p)].values,\n",
    "                           theta_grid=theta_grid_use,\n",
    "                           permutation_list_ci =pre_process_data['time_scramble'],\n",
    "                           treatment_window_ci = pre_process_data['treatment_window'],\n",
    "                           alpha=alpha)\n",
    "            sc_ci_05.append(ci_output['ci_interval'][0])\n",
    "            sc_ci_95.append(ci_output['ci_interval'][1])\n",
    "\n",
    "            ## Calculate the placebo tests for that treated unit too\n",
    "            placebo_df = sc.sc_validation_gather(counterfactual=np.array( sc_output['predict_est']['{0}_est'.format(p)].tolist() ),\n",
    "                                      actual=np.array( sc_output['predict_est']['{0}'.format(p)].tolist() ),\n",
    "                                     pre_treatment_window=pre_process_data['treatment_window'])\n",
    "            sc_placebo_pre_train.append(placebo_df['test_pre_train'].values[0])\n",
    "            sc_placebo_pre_test.append( placebo_df['test_pre_test'].values[0])\n",
    "            sc_placebo_pst_test.append( placebo_df['test_pst_test'].values[0]) \n",
    "            o+=1\n",
    "\n",
    "        sc_results['pvalues'] = sc_pv\n",
    "        sc_results['ci_lower'] = sc_ci_05\n",
    "        sc_results['ci_upper'] = sc_ci_95\n",
    "        sc_results['alpha'] = alpha\n",
    "        sc_results['test_pre_train_MAPE'] = sc_placebo_pre_train\n",
    "        sc_results['test_pre_test_MAPE'] = sc_placebo_pre_test\n",
    "        sc_results['test_pst_test_MAPE'] = sc_placebo_pst_test\n",
    "        \n",
    "        return sc_results\n",
    "\n",
    "    \n",
    "## DGP and functions to determine what types of SC models to do, and calculate primatives for SC models\n",
    "class dgp:    \n",
    "    def determine_pre_treatment_window(ci_data_output=None,\n",
    "                                      pre_treatment_window=None):\n",
    "        if pre_treatment_window ==None:\n",
    "            pre_treatment_len = ci_data_output['C_pre'].shape[0]\n",
    "            pre_t0 = int( 0.75*pre_treatment_len )\n",
    "            if pre_t0 < 1:\n",
    "                pre_t0=1\n",
    "            else:\n",
    "                pass            \n",
    "            pre_t1 = pre_treatment_len - pre_t0\n",
    "            pre_treatment_window = [pre_t0, pre_t1]\n",
    "        else:\n",
    "            pass\n",
    "        return pre_treatment_window \n",
    "    \n",
    "    def clean_and_input_data(dataset=None, \n",
    "                             treatment='treated_unit', \n",
    "                             unit_id = 'unitid',\n",
    "                             date='T',\n",
    "                             post='post', outcome='Y'):\n",
    "        \n",
    "        C_pre = dataset.loc[(dataset[treatment]==0) & (dataset[post]==0)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        C_pst = dataset.loc[(dataset[treatment]==0) & (dataset[post]==1)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pre = dataset.loc[(dataset[treatment]==1) & (dataset[post]==0)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pst = dataset.loc[(dataset[treatment]==1) & (dataset[post]==1)].pivot_table(columns=unit_id,\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        \n",
    "        permutations_subset_block = conformal_inf.time_block_permutation(data=dataset, \n",
    "                                                                         time_unit=date,\n",
    "                                                                         post=post)\n",
    "                \n",
    "        return {'C_pre':C_pre, 'C_pst':C_pst, 'T_pre':T_pre, 'T_pst':T_pst, \n",
    "                'time_scramble':permutations_subset_block[0],\n",
    "               'treatment_window':permutations_subset_block[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6a44a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doudchenko Imbens, (2016) Model\n",
    "class di:\n",
    "    def estimate_mu_omega(treatment_pre, control_pre, alpha_lambda_0):\n",
    "        alpha_0, lambda_0 = alpha_lambda_0[0], alpha_lambda_0[1]\n",
    "        elnet = ElasticNet(random_state=2736, alpha=alpha_0, l1_ratio=lambda_0)\n",
    "        elnet.fit(control_pre, treatment_pre )\n",
    "        ## Output interpretable weights\n",
    "        try:\n",
    "            df_weights= pd.DataFrame(data=zip(treatment_pre.columns,\n",
    "                                              elnet.coef_.T\n",
    "                                             ))\n",
    "        except:\n",
    "            df_weights = pd.DataFrame(index=np.arange(len(elnet.coef_)), \n",
    "                         data=elnet.coef_.T)        \n",
    "        return {'mu': elnet.intercept_, 'omega': elnet.coef_, 'weights':df_weights, 'full':elnet}\n",
    "\n",
    "    def predict_mu_omega(treatment_pre, control_pre, alpha_lambda_0, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the DI model\n",
    "        holdout_dict = di.estimate_mu_omega(treatment_holdout, control_holdout, alpha_lambda_0)\n",
    "        if treatment_pre.shape[1]==1:\n",
    "            holdout_dict['omega'] = np.array([holdout_dict['omega']])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "        diff_holdout = treatment_holdout       -\\\n",
    "            np.dot(control_holdout, holdout_dict['omega'].T)+holdout_dict['mu']        \n",
    "        diff_nonholdout = treatment_nonholdout -\\\n",
    "            np.dot(control_nonholdout, holdout_dict['omega'].T)+holdout_dict['mu']\n",
    "\n",
    "        diff_nonholdout_mse = (diff_nonholdout**2).mean()\n",
    "        diff_holdout_mse = (diff_holdout**2).mean()\n",
    "        return {'mu':     holdout_dict['mu'],\n",
    "               'omega':   holdout_dict['omega'],\n",
    "               'weights': holdout_dict['weights'],\n",
    "               'full':    holdout_dict['full'],\n",
    "               'mse_holdout': diff_holdout_mse,\n",
    "               'mse_nonholdout':diff_nonholdout_mse}\n",
    "    \n",
    "    def sc_style_results(treatment_pre, treatment_pst, control_pre, control_pst, mu,omega):\n",
    "        ## Do some normalization of the omega input\n",
    "        if len(omega.shape) > 2:\n",
    "            omega = omega.reshape(omega.shape[-2],omega.shape[-1])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        final_X = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        control_X = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        control_df = mu + pd.DataFrame(data=np.dot(control_X, omega.T), columns=[ l+'_est' for l in final_X.columns ])\n",
    "        control_df.index = final_X.index\n",
    "        \n",
    "        output_df = control_df.join(final_X)\n",
    "        \n",
    "        treatment_periods = -1*len(treatment_pst)\n",
    "        atet_df = pd.DataFrame()\n",
    "        for c in [l for l in output_df.columns if '_est' not in l]:\n",
    "            diff = output_df[c][treatment_periods:] - output_df[c+'_est'][treatment_periods:]\n",
    "            atet_df[c] = diff\n",
    "        \n",
    "        return {'atet': atet_df , 'predict_est':output_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5ca4ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here code up the functions that we will try to minimize over\n",
    "class alpha_lambda:\n",
    "    def diff(y_t,y_c, mu_x, omega_x):\n",
    "        return y_t - mu_x - np.dot(y_c,omega_x)\n",
    "\n",
    "    def alpha_lambda_transform(alpha_lambda_raw_):\n",
    "        ## Alpha is strictly greater than zero\n",
    "        ## lambda exists between 0 and 1\n",
    "        return np.exp(alpha_lambda_raw_[0]/1000), np.exp(alpha_lambda_raw_[1])/(1+np.exp(alpha_lambda_raw_[1])), \n",
    "    def alpha_lambda_diff(alpha_lambda_raw_, control_pre):\n",
    "        ## Transform the inputted alpha,lambda values \n",
    "        alpha_lambda_t = alpha_lambda.alpha_lambda_transform(alpha_lambda_raw_)\n",
    "        difference_array = []\n",
    "        ## Pick one control unit as the pretend treatment unit\n",
    "        for u in control_pre.columns:\n",
    "            control_pre_placebo_treat = control_pre[u]\n",
    "            control_pre_placebo_cntrl = control_pre[ [l for l in control_pre.columns if l !=u] ]\n",
    "\n",
    "            ## Estimate mu and lambda with that control unit\n",
    "            control_pre_placebo_w = di.estimate_mu_omega(control_pre_placebo_treat,\n",
    "                             control_pre_placebo_cntrl,\n",
    "                             alpha_lambda_t)\n",
    "            ## Estimate the difference\n",
    "            d = alpha_lambda.diff(control_pre_placebo_treat, \n",
    "                 control_pre_placebo_cntrl, \n",
    "                 control_pre_placebo_w['mu'],\n",
    "                 control_pre_placebo_w['omega'])\n",
    "            difference_array.append(d)\n",
    "        ## Estimate the difference across all the control units\n",
    "        d_mean = np.mean(difference_array)\n",
    "        return d_mean\n",
    "    def get_alpha_lambda(control_pre_input):\n",
    "        ## Initialize at a given point\n",
    "        weights = minimize(partial(alpha_lambda.alpha_lambda_diff, control_pre=control_pre_input),\n",
    "                             np.array([10.15,0.5]),\n",
    "                           method='BFGS',\n",
    "                          options={'maxiter':5000, 'gtol': 1e-07, 'disp':False})\n",
    "        return weights\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "488a1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constrained Lasso Model\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class cl:\n",
    "    def cl_obj(params, y,x) -> float:\n",
    "        return np.mean(  (y - params[0] - np.dot(x,params[1:]))**2)\n",
    "    \n",
    "    def predict_mu_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['mu'] = []\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        if treatment_pre.shape[1] > 1:\n",
    "            for t in treatment_pre.columns:\n",
    "                t_dict = cl.get_mu_omega(treatment_holdout[t], control_holdout)\n",
    "                ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "                diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict['omega'].T)+t_dict['mu']\n",
    "                diff_h_mse = (diff_h**2).mean()\n",
    "                diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict['omega'].T)+t_dict['mu']\n",
    "                diff_nh_mse = (diff_nh**2).mean()\n",
    "        \n",
    "                holdout_dict['mu'].append(t_dict['mu'])\n",
    "                holdout_dict['omega'].append(t_dict['omega'])\n",
    "                holdout_dict['weights'].append(t_dict['weights'])\n",
    "                diff_holdout_mse.append(diff_h_mse)\n",
    "                diff_nonholdout_mse.append(diff_nh_mse)\n",
    "        else:\n",
    "            \n",
    "            t_dict = cl.get_mu_omega(treatment_holdout.values.flatten(), control_holdout)\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            t_dict['omega'] = np.array([t_dict['omega']])\n",
    "            diff_h= treatment_holdout       - np.dot(control_holdout, t_dict['omega'].T)+t_dict['mu']\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout - np.dot(control_nonholdout, t_dict['omega'].T)+t_dict['mu']\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['mu'].append(t_dict['mu'])\n",
    "            holdout_dict['omega'].append(t_dict['omega'])\n",
    "            holdout_dict['weights'].append(t_dict['weights'])\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)            \n",
    "                    \n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        if len(holdout_dict['omega'].shape) > 2:\n",
    "            holdout_dict['omega'] = holdout_dict['omega'].reshape(holdout_dict['omega'].shape[-2],holdout_dict['omega'].shape[-1])\n",
    "        else:\n",
    "            pass        \n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "\n",
    "        return holdout_dict\n",
    "\n",
    "\n",
    "    def get_mu_omega(treatment_pre_input, control_pre_input):\n",
    "        n = control_pre_input.shape[1]\n",
    "        initialx = np.ones(n+1)/1\n",
    "        ## Initialize at a given point\n",
    "        weights = fmin_slsqp(partial(cl.cl_obj, y=treatment_pre_input,\n",
    "                                  x=control_pre_input),\n",
    "                             initialx,\n",
    "                             f_ieqcons=lambda x: 1-np.sum(np.abs(x[1:])),\n",
    "                         iter=50000, \n",
    "                         disp=False)\n",
    "        mu, omega = weights[0], weights[1:]\n",
    "        return {'mu':mu, 'omega':omega, 'weights':weights}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2d4eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abadie, Diamond, Hainmueller (2010) model\n",
    "## Also code up the ADH weights\n",
    "## Abadie/Diamond/Hainmueller    \n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class adh:\n",
    "    ## Define loss function\n",
    "    def loss_w(W, X, y) -> float:\n",
    "        return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "    def get_w(X, y):\n",
    "        ## Initialize at sample average with some noise\n",
    "        w_start = [1/X.shape[1]]*X.shape[1]\n",
    "    #     w_start = np.ones(X.shape[1])\n",
    "\n",
    "        weights = fmin_slsqp(partial(adh.loss_w, X=X, y=y),\n",
    "                             np.array(w_start),\n",
    "                             f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                             iter=50000, \n",
    "                             bounds=[(0.0, 1.0)]*len(w_start),\n",
    "                             disp=False)\n",
    "        return weights   \n",
    "    \n",
    "    def predict_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        if treatment_pre.shape[1] > 1:\n",
    "            for t in treatment_pre.columns:\n",
    "                t_dict = adh.get_w(control_holdout,treatment_holdout[t])\n",
    "                ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "                diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict.T)\n",
    "                diff_h_mse = (diff_h**2).mean()\n",
    "                diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict.T)\n",
    "                diff_nh_mse = (diff_nh**2).mean()\n",
    "        \n",
    "                holdout_dict['omega'].append(t_dict)\n",
    "                holdout_dict['weights'].append(t_dict)\n",
    "                diff_holdout_mse.append(diff_h_mse)\n",
    "                diff_nonholdout_mse.append(diff_nh_mse)\n",
    "        else:\n",
    "            t_dict = adh.get_w(control_holdout,treatment_holdout.values.flatten())\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            diff_h= treatment_holdout       - np.dot(control_holdout, np.array([t_dict]).T)\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout - np.dot(control_nonholdout, np.array([t_dict]).T)\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['omega'].append(t_dict)\n",
    "            holdout_dict['weights'].append(t_dict)\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)            \n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "        \n",
    "        return holdout_dict    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5f16606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conformal Inference to do inference for the SC models\n",
    "import itertools\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "rng.choice(10, size=10, replace=False)\n",
    "\n",
    "\n",
    "class conformal_inf:\n",
    "    def time_block_permutation(data=None,\n",
    "                              time_unit='date',\n",
    "                              post='W'):\n",
    "        tw =  len(data.loc[ data[post]==1][time_unit].unique())\n",
    "        treatment_window = len(data.loc[(data[post]==0)][time_unit].unique())-tw, tw\n",
    "\n",
    "        time_list = np.arange( np.sum(treatment_window) )\n",
    "        T_len = len(time_list)\n",
    "\n",
    "        ## Time block permutations\n",
    "        permutations_subset_block = []\n",
    "\n",
    "        for i in range(T_len):\n",
    "            half_A = time_list[-1*(T_len-i):]\n",
    "            half_B = time_list[0:i]\n",
    "            scrambled_list = np.concatenate([half_A, half_B]) \n",
    "            permutations_subset_block.append( list(scrambled_list)  )\n",
    "\n",
    "        return permutations_subset_block, treatment_window\n",
    "\n",
    "\n",
    "    def scrambled_residual(counterfactual, actual, \n",
    "                       scrambled_order,\n",
    "                      treatment_window):\n",
    "        '''\n",
    "        counterfactual   array of counterfactual estimates that are assumed to be ordered sequentially\n",
    "        actual           ``'' for actual values\n",
    "        scrambled_order  integer array that tells me how to scramble these\n",
    "        treatment_window list of two integers for the number of pre-treatment and post-treatment units\n",
    "        '''\n",
    "        counterfactual_ = counterfactual[scrambled_order][-1*treatment_window[1]:]\n",
    "        actual_         = actual[scrambled_order][-1*treatment_window[1]:]    \n",
    "        return actual_ - counterfactual_\n",
    "    \n",
    "    def test_statS(q, treatment_window, residual):\n",
    "        normed = np.sum(  np.power(np.abs(residual), q)  )\n",
    "        return np.power( treatment_window[1]**(-0.5)*normed , 1/q)    \n",
    "\n",
    "    def pvalue_calc(counterfactual=None,\n",
    "                    actual=None, \n",
    "                    permutation_list=None,\n",
    "                   treatment_window=None,\n",
    "                   h0 = 0):\n",
    "        control_pst = counterfactual[-1*treatment_window[1]:]\n",
    "        actual_pst  = actual[-1*treatment_window[1]:] \n",
    "        actual_pst -= h0\n",
    "\n",
    "        ## Calculate the residual\n",
    "        residual_initial = np.abs(actual_pst - control_pst)         \n",
    "        S_q = conformal_inf.test_statS(1, treatment_window, residual_initial)\n",
    "\n",
    "        ## Now do a whole bunch of treatment time scrambles\n",
    "        ## We're going to permute over all time-based permutations\n",
    "        ## Adjust the actual by the null hypothesis \n",
    "        treat_ = actual[:]\n",
    "        treat_[-1*treatment_window[1]:] -= h0\n",
    "        full_residual = np.abs(treat_ - counterfactual)\n",
    "        S_q_pi = []                \n",
    "        \n",
    "        for r in permutation_list:\n",
    "            scrambled_dates = np.array(list(r))              \n",
    "            residual_ = full_residual[scrambled_dates][-1*treatment_window[1]:]\n",
    "            S_q_pi.append(  conformal_inf.test_statS(1, treatment_window, residual_ )  )\n",
    "        p_value = 1 - np.average( (np.array(S_q_pi) < S_q ) )\n",
    "        return p_value\n",
    "    \n",
    "    def ci_calc(y_hat=None,\n",
    "               y_act=None,\n",
    "               theta_grid=None,\n",
    "                permutation_list_ci = None,\n",
    "                treatment_window_ci =None,\n",
    "               alpha=0.05):\n",
    "        pv_grid = []\n",
    "        for t in theta_grid:\n",
    "            pv = conformal_inf.pvalue_calc(counterfactual=y_hat.copy(),\n",
    "                        actual=y_act.copy(), \n",
    "                            permutation_list = permutation_list_ci,\n",
    "                           treatment_window = treatment_window_ci,\n",
    "                                 h0=t)\n",
    "            pv_grid.append(pv)   \n",
    "        ci_list = [ theta_grid[i] for i in range(len(pv_grid)) if pv_grid[i] < alpha ]\n",
    "        if len(ci_list)==0:\n",
    "            ci_list = [-9999]\n",
    "        return {'theta_list':theta_grid, 'pvalue_list':pv_grid, 'ci_list':ci_list,\n",
    "               'ci_interval':[np.min(ci_list), np.max(ci_list)]\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83611126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d1c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdf40a48",
   "metadata": {},
   "source": [
    "Test these functions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a615d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "N = 100\n",
    "initial = np.random.uniform(0,1, N)\n",
    "df = pd.DataFrame(data={'y':initial,\n",
    "                  'unit_id':np.arange(N),\n",
    "                       'time':np.zeros(N).astype(int)})\n",
    "for t in range(10):\n",
    "    entry = df.iloc[-1*N:]\n",
    "    entry['y'] = entry['y']*0.80 + np.random.normal(0,0.5,N)*0.20\n",
    "    entry.loc[[True]*N,'time'] = t\n",
    "    df = pd.concat([df,entry])\n",
    "df['treated']        = df['unit_id'].isin([0,1,2])\n",
    "df['post'] = (df['time'] > 7)\n",
    "df['W'] =     df['treated']*    df['post']\n",
    "df['unit_id'] = df['unit_id'].apply(str)\n",
    "df.loc[df['W']==True, 'y'] += 3\n",
    "## Clean data\n",
    "\n",
    "sc_dict = dgp.clean_and_input_data(dataset=df,\n",
    "                                   treatment='treated',\n",
    "                                   unit_id='unit_id',\n",
    "                                   date='time',\n",
    "                                   post='post',\n",
    "                                  outcome='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8a43ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_window_pre_treatment = dgp.determine_pre_treatment_window(ci_data_output=sc_dict, pre_treatment_window=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b41b9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ADH\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collect_sc_outputs_aggregate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [188]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f3 \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreatment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munitid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munit_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutcome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_process_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_treatment_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m f3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_df\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36msc.sc_model\u001b[0;34m(model_name, data, data_dict, pre_process_data, pre_treatment_window)\u001b[0m\n\u001b[1;32m     67\u001b[0m sc_validation \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39msc_validation(treatment_pre\u001b[38;5;241m=\u001b[39mpre_process_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_pre\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     68\u001b[0m              treatment_pst\u001b[38;5;241m=\u001b[39mpre_process_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_pst\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     69\u001b[0m              control_pre\u001b[38;5;241m=\u001b[39m  pre_process_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_pre\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m              omega\u001b[38;5;241m=\u001b[39msc_est[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momega\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     73\u001b[0m              pre_treatment_window\u001b[38;5;241m=\u001b[39mpre_treatment_window)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m## Improve on this by calling for inference results\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m sc_df_results \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_sc_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msc_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpre_process_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_process_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtheta_grid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpre_treatment_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_treatment_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msc_output, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_df\u001b[39m\u001b[38;5;124m'\u001b[39m:sc_df_results}\n",
      "Input \u001b[0;32mIn [180]\u001b[0m, in \u001b[0;36msc.collect_sc_outputs\u001b[0;34m(sc_output, pre_process_data, theta_grid, pre_treatment_window, aggregate_pst_periods, alpha)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect_sc_outputs\u001b[39m(sc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    152\u001b[0m                        pre_process_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m                        theta_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# np.arange(-10,10,0.5),\u001b[39;00m\n\u001b[1;32m    154\u001b[0m                        pre_treatment_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m                        aggregate_pst_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    156\u001b[0m                   alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aggregate_pst_periods\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m         a \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_sc_outputs_aggregate\u001b[49m(sc_output \u001b[38;5;241m=\u001b[39m sc_output,\n\u001b[1;32m    159\u001b[0m                        pre_process_data\u001b[38;5;241m=\u001b[39mpre_process_data,\n\u001b[1;32m    160\u001b[0m                        theta_grid \u001b[38;5;241m=\u001b[39m theta_grid,  \u001b[38;5;66;03m# np.arange(-10,10,0.5),\u001b[39;00m\n\u001b[1;32m    161\u001b[0m                        pre_treatment_window\u001b[38;5;241m=\u001b[39mpre_treatment_window,\n\u001b[1;32m    162\u001b[0m                   alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         a \u001b[38;5;241m=\u001b[39m collect_sc_outputs_individual(sc_output \u001b[38;5;241m=\u001b[39m sc_output,\n\u001b[1;32m    165\u001b[0m            pre_process_data\u001b[38;5;241m=\u001b[39mpre_process_data,\n\u001b[1;32m    166\u001b[0m            theta_grid \u001b[38;5;241m=\u001b[39m theta_grid,  \u001b[38;5;66;03m# np.arange(-10,10,0.5),\u001b[39;00m\n\u001b[1;32m    167\u001b[0m            pre_treatment_window\u001b[38;5;241m=\u001b[39mpre_treatment_window,\n\u001b[1;32m    168\u001b[0m           alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collect_sc_outputs_aggregate' is not defined"
     ]
    }
   ],
   "source": [
    "f3 = sc.sc_model(model_name='adh',\n",
    "        data=df,\n",
    "        data_dict={'treatment': 'treated',\n",
    "                  'date':'time',\n",
    "                  'post':'post',\n",
    "                  'unitid':'unit_id',\n",
    "                  'outcome':'y'},\n",
    "        pre_process_data=None,\n",
    "        pre_treatment_window=None)\n",
    "\n",
    "\n",
    "f3['results_df']\n",
    "# ## Figure out the alpha and lambda values\n",
    "# w=alpha_lambda.get_alpha_lambda(sc_dict['C_pre'])\n",
    "# alpha_lambda_to_use = alpha_lambda.alpha_lambda_transform(w.x)\n",
    "# ## Take the alpha and lambda values, and estimate mu and omega\n",
    "# di_est = di.predict_mu_omega(sc_dict['T_pre'], sc_dict['C_pre'], alpha_lambda_to_use, \n",
    "#                              treatment_window_pre_treatment)\n",
    "# di_output = di.sc_style_results(sc_dict['T_pre'], sc_dict['T_pst'],\n",
    "#                     sc_dict['C_pre'], sc_dict['C_pst'],\n",
    "#                         di_est['mu'],di_est['omega'])\n",
    "# di_validation = sc.sc_validation(treatment_pre=sc_dict['T_pre'], \n",
    "#                  treatment_pst=sc_dict['T_pst'],\n",
    "#                  control_pre=sc_dict['C_pre'],\n",
    "#                  control_pst=sc_dict['C_pst'], \n",
    "#                  mu=di_est['mu'],\n",
    "#                  omega=di_est['omega'],\n",
    "#                  pre_treatment_window=treatment_window_pre_treatment)\n",
    "\n",
    "# ak7 = cl.predict_mu_omega(sc_dict['T_pre'], sc_dict['C_pre'], treatment_window_pre_treatment)\n",
    "# cl_output = di.sc_style_results(sc_dict['T_pre'], sc_dict['T_pst'],\n",
    "#                     sc_dict['C_pre'], sc_dict['C_pst'],\n",
    "#                     ak7['mu'], ak7['omega'])\n",
    "# sc_validation = sc.sc_validation(treatment_pre=sc_dict['T_pre'], \n",
    "#                  treatment_pst=sc_dict['T_pst'],\n",
    "#                  control_pre=sc_dict['C_pre'],\n",
    "#                  control_pst=sc_dict['C_pst'], \n",
    "#                  mu=ak7['mu'],\n",
    "#                  omega=ak7['omega'],\n",
    "#                  pre_treatment_window=treatment_window_pre_treatment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fab144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4bf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
