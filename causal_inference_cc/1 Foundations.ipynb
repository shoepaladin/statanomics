{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference Examples\n",
    "# 1 Foundations\n",
    "Julian Hsu\n",
    "Date Made: 5 Aug 2021 \n",
    "\n",
    "### Table of Contents with Navigation Links\n",
    "* [Write Causal Models](#Section1)\n",
    "* [Simulate Data](#Section2)\n",
    "* [Bootstrapping Examples](#Section3)\n",
    "* [Bootstrapping Examples - unconfoundedness violation](#Section4)\n",
    "* [Bootstrapping Examples - overlap violation](#Section5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.discrete.conditional_models import ConditionalLogit\n",
    "\n",
    "from IPython.display import display    \n",
    "\n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "\n",
    "## Write Causal Models\n",
    "Write several functions here for estimate HTE. Each model _must_ do datasplitting.\n",
    "These functions will do a lot of predictions, so try to standardize the prediction models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardized Function for Predicting the Treatment Indicator.\n",
    "def predict_treatment_indicator(dataset, split_name, n_data_splits, feature,treatment, model):\n",
    "    treatment_hat = []\n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (dataset[split_name] != r)\n",
    "        test = (dataset[split_name]==r)\n",
    "        lg = model.fit(dataset[feature][train==True],dataset[treatment][train==True])\n",
    "        prediction = lg.predict_proba(dataset[feature][test==True])[:,1]\n",
    "        treatment_hat.extend(prediction)\n",
    "    return np.array(treatment_hat)\n",
    "\n",
    "## Standardized Function for Predicting Counterfactual Outcomes.\n",
    "def predict_counterfactual_outcomes(dataset, split_name, n_data_splits, feature, treatment, outcome,model):\n",
    "    yhat_treat = []\n",
    "    yhat_control = []\n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (dataset[split_name] != r)\n",
    "        test = (dataset[split_name]==r)            \n",
    "        bin_control = (dataset[treatment]==0)\n",
    "        bin_treat = (dataset[treatment]==1)        \n",
    "\n",
    "        ## Predict counterfactual outcomes for treatment\n",
    "        ols_treat=model.fit(dataset[feature][(bin_treat==True) & (train==True)], dataset[outcome][(bin_treat==True) & (train==True)]) \n",
    "        prediction = ols_treat.predict(dataset[feature][(test==True)])\n",
    "        yhat_treat.extend(prediction)\n",
    "        \n",
    "        ## Predict counterfactual outcomes for control\n",
    "        ols_control=model.fit(dataset[feature][(bin_control==True) & (train==True)], dataset[outcome][(bin_control==True) & (train==True)]) \n",
    "        prediction = ols_control.predict(dataset[feature][(test==True)])\n",
    "        yhat_control.extend(prediction)\n",
    "    return np.array(yhat_treat), np.array(yhat_control)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_vanilla(data_est, \n",
    "                split_name, feature_name, outcome_name, treatment_name,\n",
    "                ymodel,tmodel,\n",
    "               n_data_splits, aux_dictionary ):\n",
    "    ols = sm.OLS(data_est[outcome_name], sm.add_constant(data_est[[treatment_name]+feature_list]) ).fit()\n",
    "    return ols.params[1], ols.bse[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propbinning(data_est, \n",
    "                split_name, feature_name, outcome_name, treatment_name,\n",
    "                ymodel,tmodel,\n",
    "               n_data_splits,\n",
    "               aux_dictionary):\n",
    "        \n",
    "    data_est[split_name] = np.random.choice(n_data_splits, len(data_est), replace=True)\n",
    "    data_est = data_est.sort_values(by=split_name)\n",
    "        \n",
    "    ## Predict Treatment\n",
    "    that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "    data_est['that'] = that\n",
    "    \n",
    "    ## Sort by the probabilities and split into bins.\n",
    "    ## For each bin, estimate counterfactuals for the treatment and control groups.\n",
    "    data_est['that_bin'] = pd.qcut(data_est['that'], q=aux_dictionary['n_bins'], labels=False)    \n",
    "    min_size = data_est['that_bin'].value_counts().min()\n",
    "    \n",
    "    data_est = data_est.sort_values(by=[split_name,'that_bin'])\n",
    "    \n",
    "    yhat_treat = []\n",
    "    yhat_control = []\n",
    "    for b in range(aux_dictionary['n_bins']):\n",
    "        ## Use the first and last entry of each bin as cutpoints.    \n",
    "        bin_of_interest = (data_est['that_bin']==b)\n",
    "        for r in np.arange(n_data_splits):\n",
    "            train = (bin_of_interest==True) & (data_est[split_name] != r)\n",
    "            test = (bin_of_interest==True) & (data_est[split_name]==r)            \n",
    "            bin_control = (bin_of_interest==True) & (data_est[treatment_name]==0)\n",
    "            bin_treat = (bin_of_interest==True) & (data_est[treatment_name]==1)        \n",
    "\n",
    "            ## Predict counterfactual outcomes for treatment\n",
    "            ols_treat=ymodel.fit(data_est[feature_name][(bin_treat==True) & (train==True)], data_est[outcome_name][(bin_treat==True) & (train==True)]) \n",
    "            tpred = ols_treat.predict(data_est[feature_name][(test==True) ])\n",
    "            yhat_treat.extend(tpred)\n",
    "\n",
    "            ## Predict counterfactual outcomes for control\n",
    "            ols_control=ymodel.fit(data_est[feature_name][(bin_control==True) & (train==True)], data_est[outcome_name][(bin_control==True) & (train==True)]) \n",
    "            cpred = ols_control.predict(data_est[feature_name][(test==True)])\n",
    "            yhat_control.extend(cpred)\n",
    "\n",
    "    ## Take the difference between the counterfactuals\n",
    "    treatment_estimate = np.array(yhat_treat) - np.array(yhat_control)\n",
    "    \n",
    "    ## Output the treatment estimate and propensity scores\n",
    "    return np.average(treatment_estimate), np.std(treatment_estimate), that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inverse-propensity weighting** estimator, where asympotics come from\n",
    "Hirano, Imbens, Ridder (2004) Econometrica: \n",
    "https://scholar.harvard.edu/imbens/files/efficient_estimation_of_average_treatment_effects_using_the_estimated_propensity_score.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipw(data_est, \n",
    "                split_name, feature_name, outcome_name, treatment_name,\n",
    "                ymodel,tmodel,\n",
    "               n_data_splits,\n",
    "               aux_dictionary):\n",
    "    ## Create and sort by splits\n",
    "    data_est[split_name] = np.random.choice(n_data_splits, len(data_est), replace=True)\n",
    "    data_est.sort_values(by=split_name, inplace=True)\n",
    "\n",
    "    ## 1st Stage: Predict treatment indicator\n",
    "    that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "\n",
    "    keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "    \n",
    "    ipw_a = (data_est[outcome_name] / that)*(data_est[treatment_name]==1)\n",
    "    ipw_b = (data_est[outcome_name] / (1-that))*(data_est[treatment_name]==0)\n",
    "    \n",
    "    \n",
    "    return np.average(ipw_a[keep_these]) - np.average(ipw_b[keep_these]), np.ones(len(data_est))*-1, that,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_plm(data_est, \n",
    "                split_name, feature_name, outcome_name, treatment_name,\n",
    "                ymodel,tmodel,\n",
    "               n_data_splits,\n",
    "               aux_dictionary):\n",
    "\n",
    "    ## Create and sort by splits\n",
    "    data_est[split_name] = np.random.choice(n_data_splits, len(data_est), replace=True)\n",
    "    data_est.sort_values(by=split_name, inplace=True)\n",
    "\n",
    "    ## 1st Stage: Predict treatment indicator\n",
    "    that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "        \n",
    "    ## Residualize treatment and outcome    \n",
    "    outcome_hat = []        \n",
    "    for r in np.arange(n_data_splits):\n",
    "        train = (data_est[split_name] != r)\n",
    "        test = (data_est[split_name]==r)\n",
    "        ols = ymodel.fit(data_est[feature_name][train==True],data_est[outcome_name][train==True])\n",
    "        prediction = ols.predict(data_est[feature_name][test==True])\n",
    "        outcome_hat.extend(prediction)\n",
    "\n",
    "    outcome_hat = np.array(outcome_hat)\n",
    "    \n",
    "    treatment_residual = data_est[treatment_name].to_numpy() - that\n",
    "    outcome_residual = data_est[outcome_name].to_numpy() - outcome_hat\n",
    "    \n",
    "    ## shave off propensity scores below and under certain thresholds\n",
    "    keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "    ## Second stage OLS, for a partial linear model\n",
    "    X = sm.add_constant(treatment_residual[keep_these])\n",
    "    finalmodel_fit = sm.OLS( list(outcome_residual[keep_these]), X).fit()\n",
    "    \n",
    "    return finalmodel_fit.params[-1], finalmodel_fit.bse[-1], that\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_irm(data_est, \n",
    "                split_name, feature_name, outcome_name, treatment_name,\n",
    "                ymodel,tmodel,\n",
    "               n_data_splits, aux_dictionary ):\n",
    "    data_est[split_name] = np.random.choice(n_data_splits, len(data_est), replace=True)\n",
    "    data_est = data_est.sort_values(by=split_name)\n",
    "\n",
    "    ## 1st Stage: Predict treatment indicator\n",
    "    that = predict_treatment_indicator(data_est, split_name, n_data_splits, feature_name,treatment_name,tmodel)\n",
    "    \n",
    "    ## 2nd Stage: Predict counterfactual outcomes\n",
    "    yhat_treat, yhat_control = predict_counterfactual_outcomes(data_est, split_name, n_data_splits, feature_name, treatment_name, outcome_name,ymodel)\n",
    "    \n",
    "    ## Residualize:\n",
    "    y_control_residual = data_est[outcome_name]- yhat_control\n",
    "    y_treat_residual = data_est[outcome_name]- yhat_treat    \n",
    "    \n",
    "    ## IPWRA Estimator on the residuals\n",
    "    ra_term = yhat_treat - yhat_control    \n",
    "\n",
    "    first_fraction = (data_est[treatment_name]==1)*(y_treat_residual) / that\n",
    "    second_fraction = (data_est[treatment_name]==0)*(y_control_residual) / (1-that)\n",
    "    ipw_term = first_fraction - second_fraction\n",
    "    \n",
    "    treatment_estimate = ra_term + ipw_term\n",
    "    keep_these = (that >= aux_dictionary['lower']) & (that <= aux_dictionary['upper'])    \n",
    "        \n",
    "    treatment_estimate = treatment_estimate[keep_these]\n",
    "    \n",
    "    ## standard error\n",
    "    se_est = np.sqrt(np.var(treatment_estimate))\n",
    "    \n",
    "    return np.mean(treatment_estimate), se_est, that[keep_these]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "\n",
    "## Bring in Simulated Data\n",
    "Pretend we've never seen this data before, and do balance checks between treatment and control \n",
    "\n",
    "For fun, use the Friedman function: https://www.sfu.ca/~ssurjano/fried.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    N = 2000\n",
    "    \n",
    "    cov = [[1.00, 0.08, 0.05, 0.05],\n",
    "           [0.08, 1.00,-0.08,-0.02],\n",
    "           [0.05,-0.08, 1.00,-0.10],\n",
    "           [0.05,-0.02,-0.10, 1.00]]\n",
    "    cov = np.eye(4)\n",
    "    X = np.random.multivariate_normal(np.zeros(4), cov,N)\n",
    "    x1,x2,x3,x4= X[:,0],X[:,1],X[:,2],X[:,3]\n",
    "\n",
    "    treatment_latent = 2*np.sin( np.pi * x4 * x3) + 10*(x2-0.5)**2 - 10*x1\n",
    "    m,s = np.average(treatment_latent), np.std(treatment_latent)\n",
    "\n",
    "    treatment_latent = (treatment_latent - m) / s\n",
    "    \n",
    "    random_t = np.random.normal(0,1,N)\n",
    "    \n",
    "    treatment_latent += random_t\n",
    "    \n",
    "    treatment = np.array( np.exp(treatment_latent) / (1+ np.exp(treatment_latent)) > np.random.uniform(0,1,N) ).astype(np.int32)\n",
    "\n",
    "#     Y = 100 +0.5*x1 - 6*x2 + -2*x4*x1 + 0.5*x1*x2 - 7*(x3+1)**(0.5) + 8/(0.5+x3+x4)\n",
    "    Y = 100 + 10*np.sin( np.pi * x1 * x2) + 20*(x3-0.5)**2 - 10*x4\n",
    "#     GT = np.std(Y)\n",
    "    random_y = np.random.normal(0,1,N)\n",
    "\n",
    "    GT = 5\n",
    "    Y += np.random.normal(1,2,N)\n",
    "    Y += GT*(treatment==1) \n",
    "    \n",
    "    df_est = pd.DataFrame({'x1':x1, 'x2':x2,'x3':x3,'x4':x4,'treatment':treatment, 'Y':Y, 'GT':GT} )\n",
    "    df_est['x1_2'] = df_est['x1'].pow(2)\n",
    "    df_est['x2_2'] = df_est['x2'].pow(2)\n",
    "    df_est['x3_2'] = df_est['x3'].pow(2)\n",
    "    df_est['x4_2'] = df_est['x4'].pow(2)    \n",
    "    return df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_iter = 500\n",
    "## treatment prediction models\n",
    "t_models = {}\n",
    "t_models['LogitCV'] = LogisticRegressionCV(cv=5, random_state=27, n_jobs=-1)\n",
    "t_models['logit'] = LogisticRegression(penalty='l2',solver='lbfgs', C=1, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L1_C2'] = LogisticRegression(penalty='l1',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L2_C5'] = LogisticRegression(penalty='l2',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['rf_md10'] = RandomForestClassifier(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "t_models['rf_md3'] = RandomForestClassifier(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "t_models['nn'] = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1,max_iter=model_max_iter)\n",
    "## outcome prediction models\n",
    "y_models = {}\n",
    "y_models['LassoCV'] = LassoCV(cv=5, n_jobs=-1, normalize=True, random_state=27)\n",
    "y_models['ols'] = LinearRegression()\n",
    "y_models['lasso_a2'] = Lasso(alpha=2,max_iter=model_max_iter)\n",
    "y_models['ridge_a2'] = Ridge(alpha=2,max_iter=model_max_iter)\n",
    "y_models['rf_md10'] = RandomForestRegressor(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "y_models['rf_md3'] = RandomForestRegressor(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "y_models['nn'] = MLPRegressor(alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1, max_iter=model_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_splits = 4\n",
    "aux_dictionary = {'n_bins': 2, 'n_trees':2, 'max_depth':2, \n",
    "                  'upper':0.999, 'lower':0.001,\n",
    "                  'subsample_ratio':0.5}\n",
    "bootstrap_number = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "\n",
    "feature_list = [x for x in df.columns if 'x' in x]\n",
    "\n",
    "ols = ols_vanilla(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "pbin = propbinning(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "plm = dml_plm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "irm = dml_irm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "ip = ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "df = df.sort_values(by='splits')    \n",
    "\n",
    "## Predict Treatment\n",
    "that = predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "df['that'] = that\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n",
    "control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "print(control_range_to_remove)\n",
    "\n",
    "df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "\n",
    "## Bootstrapping\n",
    "* Bootstrap results using random datasets when all three assumptions are satisfied.\n",
    "* Bootstrap results when the unconfoundedness assumption is violated. Do this by removing one fot the features from training.\n",
    "* Bootstrap results when the overlap assumption is violated. Do this by removing control observations with propensities near the median treatment obervation propensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x = []\n",
    "pbin_x= []\n",
    "plm_x = []\n",
    "irm_x = []\n",
    "ipw_x = []\n",
    "\n",
    "ols_x_unconf = []\n",
    "pbin_x_unconf= []\n",
    "plm_x_unconf = []\n",
    "irm_x_unconf = []\n",
    "ipw_x_unconf = []\n",
    "\n",
    "ols_x_overlap = []\n",
    "pbin_x_overlap= []\n",
    "plm_x_overlap = []\n",
    "irm_x_overlap = []\n",
    "ipw_x_overlap = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(bootstrap_number):\n",
    "    df = generate_data()\n",
    "    ols = ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x.append(ols[0])\n",
    "    pbin_x.append(pbin[0])\n",
    "    plm_x.append(plm[0])\n",
    "    irm_x.append(irm[0])    \n",
    "    ipw_x.append(ip[0])   \n",
    "    \n",
    "    ols = ols_vanilla(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = propbinning(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = dml_plm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = dml_irm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = ipw(df, \n",
    "                'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x_unconf.append(ols[0])\n",
    "    pbin_x_unconf.append(pbin[0])\n",
    "    plm_x_unconf.append(plm[0])\n",
    "    irm_x_unconf.append(irm[0])    \n",
    "    ipw_x_unconf.append(ip[0])        \n",
    "\n",
    "\n",
    "    df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "    df = df.sort_values(by='splits')    \n",
    "    ## Predict Treatment\n",
    "    that = predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "    df['that'] = that    \n",
    "    control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "    df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "\n",
    "\n",
    "    ols = ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "\n",
    "    ols_x_overlap.append(ols[0])\n",
    "    pbin_x_overlap.append(pbin[0])\n",
    "    plm_x_overlap.append(plm[0])\n",
    "    irm_x_overlap.append(irm[0])    \n",
    "    ipw_x_overlap.append(ip[0])        \n",
    "\n",
    "ols_x = np.array(ols_x) - 5\n",
    "pbin_x = np.array(pbin_x) - 5\n",
    "plm_x = np.array(plm_x) - 5\n",
    "irm_x = np.array(irm_x) - 5\n",
    "ipw_x = np.array(ipw_x) - 5\n",
    "\n",
    "ols_x_unconf = np.array(ols_x_unconf) - 5\n",
    "pbin_x_unconf = np.array(pbin_x_unconf) - 5\n",
    "plm_x_unconf = np.array(plm_x_unconf) - 5\n",
    "irm_x_unconf = np.array(irm_x_unconf) - 5\n",
    "ipw_x_unconf = np.array(ipw_x_unconf) - 5    \n",
    "\n",
    "ols_x_overlap = np.array(ols_x_overlap) - 5\n",
    "pbin_x_overlap = np.array(pbin_x_overlap) - 5\n",
    "plm_x_overlap = np.array(plm_x_overlap) - 5\n",
    "irm_x_overlap = np.array(irm_x_overlap) - 5\n",
    "ipw_x_overlap = np.array(ipw_x_overlap) - 5    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: 0.013  , MED: 0.012, IQR: 0.013 to 0.012\n",
      "AVG: -0.047  , MED: -0.026, IQR: -0.047 to -0.026\n",
      "AVG: -0.023  , MED: -0.034, IQR: -0.023 to -0.034\n",
      "AVG: -0.017  , MED: -0.035, IQR: -0.017 to -0.035\n",
      "AVG: 0.271  , MED: 0.783, IQR: 0.271 to 0.783\n",
      "\n",
      "AVG: 0.013  , MED: 0.012, IQR: 0.013 to 0.012\n",
      "AVG: -0.149  , MED: -0.166, IQR: -0.149 to -0.166\n",
      "AVG: -0.006  , MED: -0.093, IQR: -0.006 to -0.093\n",
      "AVG: 0.040  , MED: -0.123, IQR: 0.040 to -0.123\n",
      "AVG: 0.656  , MED: 1.266, IQR: 0.656 to 1.266\n",
      "\n",
      "AVG: 0.775  , MED: 0.754, IQR: 0.775 to 0.754\n",
      "AVG: -0.203  , MED: 0.135, IQR: -0.203 to 0.135\n",
      "AVG: 0.942  , MED: 0.919, IQR: 0.942 to 0.919\n",
      "AVG: 2.455  , MED: 2.718, IQR: 2.455 to 2.718\n",
      "AVG: 24.043  , MED: 25.236, IQR: 24.043 to 25.236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_avg_med_iqr(ols_x)    \n",
    "print_avg_med_iqr(pbin_x)    \n",
    "print_avg_med_iqr(plm_x)    \n",
    "print_avg_med_iqr(irm_x)    \n",
    "print_avg_med_iqr(ipw_x)    \n",
    "\n",
    "print('')\n",
    "print_avg_med_iqr(ols_x_unconf) \n",
    "print_avg_med_iqr(pbin_x_unconf)    \n",
    "print_avg_med_iqr(plm_x_unconf)    \n",
    "print_avg_med_iqr(irm_x_unconf)    \n",
    "print_avg_med_iqr(ipw_x_unconf)    \n",
    "\n",
    "print('')\n",
    "print_avg_med_iqr(ols_x_overlap)    \n",
    "print_avg_med_iqr(pbin_x_overlap)    \n",
    "print_avg_med_iqr(plm_x_overlap)    \n",
    "print_avg_med_iqr(irm_x_overlap)    \n",
    "print_avg_med_iqr(ipw_x_overlap[~np.isnan(ipw_x_overlap)])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
